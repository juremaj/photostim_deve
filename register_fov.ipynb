{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa30f23",
   "metadata": {},
   "source": [
    "# Code for registering 2d FOVs using keypoint registration\n",
    "1) TODO: based on this improve the CP target-selection script (the segmentation will be way better with motion correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f046f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tifffile as tiff\n",
    "from skimage.transform import warp, resize\n",
    "import napari\n",
    "\n",
    "\n",
    "from photostim_deve.image_analysis.plot import plot_motcorr_comparison, plot_segmentation_overlay_dict, plot_image_seg_xy_stim, plot_keypoints_scatter\n",
    "from photostim_deve.image_analysis.io import get_all_fov_image, get_s2p_image, get_xy_stim, save_keypoints, load_keypoints, get_t2p_s2p_indices_session, get_s2p_rois_filt\n",
    "from photostim_deve.image_analysis.segment import segment_fov_cpsam, get_cent_from_seg\n",
    "from photostim_deve.image_analysis.register import register_keypoints_affine, match_ref_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "subject = 'jm065'\n",
    "sat_perc = 99.99\n",
    "\n",
    "fov_imsize = (1024, 1024)  # size of the FOV in pixels (assumed square)\n",
    "s2p_imsize = (512, 512)  # size used for Suite2p processing\n",
    "\n",
    "n_stim_cell = 45 # how many 'cell' points were stimulated\n",
    "n_stim_ctrl = 5 # how many 'control' points were stimulated\n",
    "\n",
    "session_reg_idx = 0  # index of the session used as reference for FOV registration across sessions (usually should be 0 for the first session)\n",
    "\n",
    "force_recompute = False  # whether to force recomputation of motion correction and segmentation even if files already exist\n",
    "\n",
    "# motion correction\n",
    "run_motcorr = True\n",
    "nimg_init = 128  # number of frames used to compute the reference image for motion correction\n",
    "\n",
    "# choosing Suite2p ROIs to consider for matching\n",
    "filt_by = 't2p'  # filter Suite2p ROIs by 't2p' (track2p matching) or 'iscell_cell_prob' or 'iscell_manual_cur'\n",
    "track2p_dirname='track2p_a' # this applies only if above filt_by is 't2p' (name of the track2p directory to get the matching indices from)\n",
    "cell_prob_thr = 0.5 # this applies only if above filt_by is 'iscell_cell_prob' (threshold for cell probability to consider an ROI as a cell based on s2p classifier)\n",
    "\n",
    "# parameters used for matching\n",
    "max_dist_px = 7 # hard threshold on distance in pixels for matching points between two sets of coordinates\n",
    "\n",
    "# session type (either '_a' - spontaneous or '_s' - evoked) \n",
    "session_type = '_a' # TODO: PAY ATTENTION FOR NOW THAT IT MATCHES THE track2p_dirname!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_path = os.path.join('data_proc', 'jm', subject)\n",
    "all_session_path = sorted([os.path.join(subject_path, d) for d in os.listdir(subject_path) if os.path.isdir(os.path.join(subject_path, d)) and session_type in d])\n",
    "session_path = all_session_path[session_reg_idx]\n",
    "\n",
    "match_save_dir = os.path.join(session_path, 'match_s2p_fov_stim')\n",
    "\n",
    "keypoints_save_path = os.path.join(session_path, 'fov_reg_keypoints.csv')\n",
    "\n",
    "\n",
    "fov_s2p_px_fact = fov_imsize[0] / s2p_imsize[0] # both have the same aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7792f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fov_image = get_all_fov_image(subject_path, \n",
    "                                  session_type=session_type,\n",
    "                                  session_reg_idx = session_reg_idx, \n",
    "                                  run_motcorr=run_motcorr, \n",
    "                                  fov_imsize=fov_imsize, \n",
    "                                  nimg_init=nimg_init,\n",
    "                                  force_recompute=force_recompute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_motcorr_comparison(all_fov_image, sat_perc=sat_perc, crop=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a763fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fov_image_seg = segment_fov_cpsam(all_fov_image, flow_threshold=0.4, cellprob_threshold=0.0, force_recompute=force_recompute, save_path=session_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation_overlay_dict(all_fov_image_seg, sat_perc=sat_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_image = get_s2p_image(session_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stim, y_stim = get_xy_stim(session_path, session_type=session_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_seg_xy_stim(all_fov_image['1100nm'], x_stim=x_stim, y_stim=y_stim, segmentation=all_fov_image_seg['1100nm_seg'], sat_perc=sat_perc, fov_s2p_px_fact=fov_s2p_px_fact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c923b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_image_upscaled = resize(s2p_image, fov_imsize, preserve_range=True, anti_aliasing=True).astype(s2p_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(keypoints_save_path) or force_recompute:\n",
    "    import napari\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    viewer.add_image(s2p_image_upscaled, name='s2p_mean_image', colormap='green', contrast_limits=(np.percentile(s2p_image_upscaled, 0.1), np.percentile(s2p_image_upscaled, sat_perc)))\n",
    "    viewer.add_points(name='s2p_keypoints', size=5, face_color='green')\n",
    "    viewer.add_image(all_fov_image['1100nm'], name='fov_1100nm', colormap='magenta', contrast_limits=(np.percentile(all_fov_image['1100nm'], 0.1), np.percentile(all_fov_image['1100nm'], sat_perc)))\n",
    "    viewer.add_points(name='fov_1100nm_keypoints', size=5, face_color='magenta')\n",
    "    napari.run()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(keypoints_save_path) or force_recompute:\n",
    "    save_keypoints(viewer, keypoints_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fcfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_kp_s2p, y_kp_s2p, x_kp_fov, y_kp_fov = load_keypoints(keypoints_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92debb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_kp_fov_reg, y_kp_fov_reg, transform = register_keypoints_affine(x_kp_s2p, y_kp_s2p, x_kp_fov, y_kp_fov)\n",
    "plot_keypoints_scatter(x_kp_s2p, y_kp_s2p, x_kp_fov, y_kp_fov, x_kp_fov_reg, y_kp_fov_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stim_upscaled, y_stim_upscaled = x_stim * fov_s2p_px_fact, y_stim * fov_s2p_px_fact\n",
    "x_stim_upscaled_reg, y_stim_upscaled_reg = transform.inverse(np.stack([x_stim_upscaled, y_stim_upscaled], axis=1)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66762cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get and transform the centroids of the 1100nm CPs\n",
    "x_fov, y_fov = get_cent_from_seg(all_fov_image_seg['1100nm_seg'])\n",
    "x_fov_reg, y_fov_reg = transform.inverse(np.stack([x_fov, y_fov], axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d399d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply transform to the image\n",
    "fov_image = all_fov_image['1100nm']\n",
    "fov_image_reg = warp(fov_image, inverse_map=transform.inverse, output_shape=fov_imsize)\n",
    "\n",
    "fov_seg = all_fov_image_seg['1100nm_seg']\n",
    "fov_seg_reg = warp(fov_seg, inverse_map=transform.inverse, output_shape=fov_imsize, order=0, preserve_range=True).astype(fov_seg.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03021a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_image_upscaled = resize(s2p_image, fov_imsize, preserve_range=True, anti_aliasing=True).astype(s2p_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2p_idxs_session = get_t2p_s2p_indices_session(subject_path, track2p_dirname=track2p_dirname, session_reg_idx=session_reg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_s2p, x_s2p_med, y_s2p_med, idxs_filt = get_s2p_rois_filt(session_path, filt_by='t2p', t2p_idxs_session=t2p_idxs_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s2p_med_upscaled = x_s2p_med * fov_s2p_px_fact\n",
    "y_s2p_med_upscaled = y_s2p_med * fov_s2p_px_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind_s2p_fov, col_ind_s2p_fov = match_ref_moving(x_s2p_med_upscaled, y_s2p_med_upscaled, x_fov_reg, y_fov_reg, max_dist_px=max_dist_px)\n",
    "row_ind_s2p_stim, col_ind_s2p_stim = match_ref_moving(x_s2p_med_upscaled, y_s2p_med_upscaled, x_stim_upscaled_reg, y_stim_upscaled_reg, max_dist_px=max_dist_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(fov_image_reg, name='fov_1100nm_registered', colormap='magenta', blending='additive', contrast_limits=(np.percentile(fov_image_reg, 0.1), np.percentile(fov_image_reg, 99.9)))\n",
    "viewer.add_image(s2p_image_upscaled, name='s2p_mean_image_registered', colormap='green', blending='additive', contrast_limits=(np.percentile(s2p_image_upscaled, 0.1), np.percentile(s2p_image_upscaled, sat_perc)))\n",
    "viewer.add_image(fov_seg_reg>0, name='fov_1100nm_seg_registered', opacity=0.3, colormap='magenta')\n",
    "viewer.add_points(np.stack([x_s2p_med_upscaled, y_s2p_med_upscaled], axis=1), name='s2p_rois_medians_upscaled', size=5, face_color='green')\n",
    "viewer.add_points(np.stack([x_stim_upscaled_reg, y_stim_upscaled_reg], axis=1), name='stim_points_registered', symbol='x', size=5, face_color='cyan')\n",
    "viewer.add_points(np.stack([x_fov_reg[col_ind_s2p_fov], y_fov_reg[col_ind_s2p_fov]], axis=1), name='matched_centroids_1100nm', size=15, border_color='yellow', border_width=0.2, face_color=[0,0,0,0], opacity=0.5)\n",
    "viewer.add_points(np.stack([x_stim_upscaled_reg[col_ind_s2p_stim], y_stim_upscaled_reg[col_ind_s2p_stim]], axis=1), name='matched_stim_points', symbol='s', size=20, border_color='white', border_width=0.2, face_color=[0,0,0,0], opacity=0.5)\n",
    "napari.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate proportions\n",
    "n_stim_to_s2p = len(col_ind_s2p_stim)\n",
    "n_fov_to_s2p = len(col_ind_s2p_fov)\n",
    "n_s2p = len(x_s2p_med)\n",
    "\n",
    "prop_stim_to_s2p = n_stim_to_s2p / n_stim_cell\n",
    "prop_fov_to_s2p = n_fov_to_s2p / n_s2p\n",
    "\n",
    "print(f'Identified {n_fov_to_s2p} (/ {n_s2p}) tracked cells as expressing opsin, corresponding to: {prop_fov_to_s2p:.3f}.')\n",
    "print(f'Tracked {n_stim_to_s2p} (/ {n_stim_cell}) stimulated cells, corresponding to: {prop_stim_to_s2p:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffdd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: export this in a format that will be easy to match with longipy\n",
    "# make a numpy array with indexes that are True for stimulated & tracked cells\n",
    "is_stim_and_s2p = row_ind_s2p_stim\n",
    "is_stim_and_s2p_idx = col_ind_s2p_stim # the index of that ROI according to the order of stimulation (from Bruker MarkPoints)\n",
    "is_fov_and_s2p = row_ind_s2p_fov\n",
    "is_fov_and_s2p_idx = col_ind_s2p_fov # the index of that ROI in the CP segmentation (for now not really needed)\n",
    "\n",
    "# Save these in the a separate folder\n",
    "if not os.path.exists(match_save_dir):\n",
    "    os.makedirs(match_save_dir)\n",
    "else:\n",
    "    print(f'Matching save directory {match_save_dir} already exists.')\n",
    "\n",
    "np.save(os.path.join(match_save_dir, 'is_stim_and_s2p.npy'), is_stim_and_s2p)\n",
    "np.save(os.path.join(match_save_dir, 'is_stim_and_s2p_idx.npy'), is_stim_and_s2p_idx)\n",
    "np.save(os.path.join(match_save_dir, 'is_fov_and_s2p.npy'), is_fov_and_s2p)\n",
    "np.save(os.path.join(match_save_dir, 'is_fov_and_s2p_idx.npy'), is_fov_and_s2p_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
