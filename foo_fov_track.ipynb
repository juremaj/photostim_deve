{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tifffile as tiff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87d9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def points_to_homogeneous(points):\n",
    "    ''' Converts 2D points to homogeneous coordinates.\n",
    "    \n",
    "    Args:\n",
    "        points (array): Nx2 array of 2D points\n",
    "    Returns:\n",
    "        array: Nx3 array of homogeneous coordinates\n",
    "    '''\n",
    "    N = points.shape[0]\n",
    "    ones = np.ones((N, 1), dtype=np.float32)\n",
    "    points_homogeneous = np.concatenate([points, ones], axis=1)\n",
    "    assert(points_homogeneous.shape == (N, 3))\n",
    "    return points_homogeneous\n",
    "\n",
    "def get_Ai(xi_vector, xi_prime_vector):\n",
    "    ''' Returns the A_i matrix discussed in the lecture for input vectors.\n",
    "    \n",
    "    Args:\n",
    "        xi_vector (array): the x_i vector in homogeneous coordinates\n",
    "        xi_vector_prime (array): the x_i_prime vector in homogeneous coordinates\n",
    "    '''\n",
    "    assert(xi_vector.shape == (3,) and xi_prime_vector.shape == (3,))\n",
    "    zero_vector = np.zeros((3,), dtype=np.float32)\n",
    "    xi, yi, wi = xi_prime_vector\n",
    "    \n",
    "    Ai = np.stack([\n",
    "        np.concatenate([zero_vector, -wi*xi_vector, yi*xi_vector]),\n",
    "        np.concatenate([wi*xi_vector, zero_vector, -xi*xi_vector]),\n",
    "        # np.concatenate([-yi*xi_vector, xi*xi_vector, zero_vector]) this is not needed, so we comment it out\n",
    "    ])\n",
    "    assert(Ai.shape == (2, 9))\n",
    "    return Ai\n",
    "\n",
    "def get_A(points_source, points_target):\n",
    "    ''' Returns the A matrix discussed in the lecture.\n",
    "    \n",
    "    Args:\n",
    "        points_source (array): 3D homogeneous points from source image\n",
    "        points_target (array): 3D homogeneous points from target image\n",
    "    '''\n",
    "    N = points_source.shape[0]\n",
    "    correspondence_pairs = zip(points_source, points_target)\n",
    "    \n",
    "    A = np.concatenate([get_Ai(p1, p2) for (p1, p2) in correspondence_pairs])\n",
    "    assert(A.shape == (2*N, 9))\n",
    "    return A\n",
    "\n",
    "def get_homography(points_source, points_target):\n",
    "    ''' Returns the homography H.\n",
    "    \n",
    "    Args:\n",
    "        points_source (array): 3D homogeneous points from source image\n",
    "        points_target (array): 3D homogeneous points from target image        \n",
    "    '''\n",
    "    A = get_A(points_source, points_target)\n",
    "    u, s, vh = np.linalg.svd(A)\n",
    "    H = vh[-1].reshape(3, 3)\n",
    "    H = H / H[2, 2]\n",
    "    return H\n",
    "\n",
    "def get_affine(points_source, points_target):\n",
    "    ''' Returns the affine transformation matrix M computed using least squares.\n",
    "\n",
    "    Args:\n",
    "        points_source (array): Nx3 homogeneous points from source image\n",
    "        points_target (array): Nx3 homogeneous points from target image        \n",
    "    '''\n",
    "    N = points_source.shape[0]\n",
    "    assert(points_source.shape == (N, 3))\n",
    "    assert(points_target.shape == (N, 3))\n",
    "\n",
    "    A = []\n",
    "    b = []\n",
    "\n",
    "    for i in range(N):\n",
    "        x, y, _ = points_source[i]\n",
    "        xp, yp, _ = points_target[i]\n",
    "\n",
    "        A.append([x, y, 1, 0, 0, 0])\n",
    "        A.append([0, 0, 0, x, y, 1])\n",
    "\n",
    "        b.append(xp)\n",
    "        b.append(yp)\n",
    "\n",
    "    A = np.asarray(A, dtype=np.float32)   # shape (2N, 6)\n",
    "    b = np.asarray(b, dtype=np.float32)   # shape (2N,)\n",
    "\n",
    "    # Least squares solution\n",
    "    theta, _, _, _ = np.linalg.lstsq(A, b, rcond=None)\n",
    "\n",
    "    # Construct affine matrix\n",
    "    M = np.array([\n",
    "        [theta[0], theta[1], theta[2]],\n",
    "        [theta[3], theta[4], theta[5]],\n",
    "        [0,        0,        1       ]\n",
    "    ], dtype=np.float32)\n",
    "\n",
    "    return M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse = 'jm065'\n",
    "sat_perc = 99.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085599c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_path = f'data_proc/jm/{mouse}/'\n",
    "\n",
    "# now find all subfolders in mouse_path that start with '_a' in the end\n",
    "subfolders = [f.path for f in os.scandir(mouse_path) if f.is_dir() and f.name.endswith('_a')]\n",
    "subfolders.sort()\n",
    "print(subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93325ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now in each in each of these find the fov tseries and append them to a list\n",
    "\n",
    "wl = '1100nm'\n",
    "\n",
    "fov_tseries_1100 = []\n",
    "\n",
    "for p in subfolders:\n",
    "    print(p)\n",
    "    wl_path = os.path.join(p, 'fov', wl)\n",
    "    # now in this path find a folder starting with 'TSeries' (there should only be one)\n",
    "    tseries_folders = [f.path for f in os.scandir(wl_path) if f.is_dir() and f.name.startswith('TSeries')]\n",
    "    tseries_folder = tseries_folders[0] \n",
    "    # now in this path find a file ending wiith '.tif'\n",
    "\n",
    "    tif_files = [f.path for f in os.scandir(tseries_folder) if f.is_file() and f.name.endswith('.tif')]\n",
    "    tif_file = tif_files[0]\n",
    "\n",
    "    print(tif_file)\n",
    "\n",
    "    # now read the tiff file, compute the mean across frames and append to fov_tseries\n",
    "    # TODO: motion correction! (just use the suite2p script, probably the easiest)\n",
    "    tiff_data = tiff.imread(tif_file)\n",
    "    tiff_mean = tiff_data.mean(axis=0)\n",
    "    fov_tseries_1100.append(tiff_mean)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0c70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the suite2p mean images at 920 nm average (in ops.npy\n",
    "fov_suite2p_920 = []\n",
    "for p in subfolders:\n",
    "    print(p)\n",
    "    suite2p_path = os.path.join(p, 'suite2p', 'plane0')\n",
    "    ops_file = os.path.join(suite2p_path, 'ops.npy')\n",
    "    ops = np.load(ops_file, allow_pickle=True).item()\n",
    "    mean_img_920 = ops['meanImg']\n",
    "    fov_suite2p_920.append(mean_img_920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98eed27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot them\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ages = ['P8', 'P9', 'P10', 'P11', 'P12', 'P13']\n",
    "\n",
    "fig, axs = plt.subplots(1, len(fov_tseries_1100), figsize=(30, 5), dpi=500)\n",
    "if len(fov_tseries_1100) == 1:\n",
    "    axs = [axs]  # make it iterable\n",
    "for i, ax in enumerate(axs):\n",
    "    img = fov_tseries_1100[i]\n",
    "    img_sat = np.clip(img, 0, np.percentile(img, sat_perc))\n",
    "    ax.imshow(img_sat, cmap='gray')\n",
    "    ax.set_title(f'{ages[i]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "# set suptitle\n",
    "fig.suptitle(f'Mouse {mouse} FOVs at 1100nm', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78812975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot them\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ages = ['P8', 'P9', 'P10', 'P11', 'P12', 'P13']\n",
    "\n",
    "fig, axs = plt.subplots(1, len(fov_suite2p_920), figsize=(30, 5), dpi=500)\n",
    "if len(fov_suite2p_920) == 1:\n",
    "    axs = [axs]  # make it iterable\n",
    "for i, ax in enumerate(axs):\n",
    "    img = fov_suite2p_920[i]\n",
    "    img_sat = np.clip(img, 0, np.percentile(img, sat_perc))\n",
    "    ax.imshow(img_sat, cmap='gray')\n",
    "    ax.set_title(f'{ages[i]}')\n",
    "    ax.axis('off')\n",
    "\n",
    "# set suptitle\n",
    "fig.suptitle(f'Mouse {mouse} FOVs at 1100nm', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1af0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_r = fov_tseries_1100\n",
    "all_imgs_g = fov_suite2p_920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c140ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now open in napari to mark keypoints\n",
    "man_curate = False\n",
    "\n",
    "if man_curate:\n",
    "    viewer = napari.Viewer()\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    for i, img_r in enumerate(all_imgs_r):\n",
    "        viewer.add_image(img_r, name=f'Red channel image {i}', contrast_limits=[0, np.percentile(img_r, sat_perc)])\n",
    "        viewer.add_points(name=f'Red channel keypoints {i}')\n",
    "\n",
    "    for i, img_g in enumerate(all_imgs_g):\n",
    "        viewer.add_image(img_g, name=f'Green channel image {i}')\n",
    "        viewer.add_points(name=f'Green channel keypoints {i}')\n",
    "\n",
    "    napari.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7a1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save points as csv files for later processing\n",
    "for layer in viewer.layers:\n",
    "    if isinstance(layer, napari.layers.Points):\n",
    "        layer.data = np.array(layer.data)  # ensure data is numpy array\n",
    "        np.savetxt(f'{layer.name}_keypoints.csv', layer.data, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the keypoints using a text reader\n",
    "from numpy import loadtxt\n",
    "# from pandas import read_csv\n",
    "\n",
    "all_keypoints_r = []\n",
    "all_keypoints_g = []\n",
    "\n",
    "for i in range(len(all_imgs_r)):\n",
    "    keypoints_r = loadtxt(f'Red channel keypoints {i}_keypoints.csv', delimiter=',')\n",
    "    # keypoints_g = read_csv(f'Green channel keypoints {i}_keypoints.csv', delimiter=',').values\n",
    "    all_keypoints_r.append(keypoints_r)\n",
    "    # all_keypoints_g.append(keypoints_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66486f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imgs_r[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb0a61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keypoints_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b58f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now show images side by side with keypoints connected by line\n",
    "img_stack = np.concatenate((all_imgs_r[0], all_imgs_r[1]), axis=-1)\n",
    "fig, ax = plt.subplots(dpi=500)\n",
    "ax.imshow(img_stack, cmap='gray', vmin=0, vmax=np.percentile(img_stack, sat_perc))\n",
    "ax.axvline(x=all_imgs_r[0].shape[1], color='white', linewidth=1)  # line separating images\n",
    "\n",
    "#enumerate and zip\n",
    "for i in range(len(all_keypoints_r[0])):\n",
    "    p0 = all_keypoints_r[0][i]\n",
    "    p1 = all_keypoints_r[1][i]\n",
    "\n",
    "    ax.plot([p0[1], p1[1] + all_imgs_r[0].shape[1]], [p0[0], p1[0]], f'C{i}--', linewidth=0.5)  # note the offset for x in second image\n",
    "    ax.scatter(p0[1], p0[0], edgecolors=f'C{i}', facecolors='none', linewidth=0.5)  # point in first image\n",
    "    ax.scatter(p1[1] + all_imgs_r[0].shape[1], p1[0], edgecolors=f'C{i}', facecolors='none', linewidth=0.5)  # point in second image\n",
    "\n",
    "# turn off axis\n",
    "ax.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a0300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first test on points\n",
    "pts_ref = all_keypoints_r[0]\n",
    "pts_mov = all_keypoints_r[1]\n",
    "\n",
    "pts_ref_homogeneous = points_to_homogeneous(pts_ref)\n",
    "pts_mov_homogeneous = points_to_homogeneous(pts_mov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_type = 'affine'\n",
    "\n",
    "# if transform_type == 'homography':\n",
    "#     A = get_homography(pts_mov_homogeneous, pts_ref_homogeneous)\n",
    "# elif transform_type == 'affine':\n",
    "#     A = get_affine(pts_mov_homogeneous, pts_ref_homogeneous)\n",
    "A = get_homography(pts_mov_homogeneous, pts_ref_homogeneous) if transform_type == 'homography' else get_affine(pts_mov_homogeneous, pts_ref_homogeneous)\n",
    "\n",
    "pts_mov_homogeneous_transformed = (A @ pts_mov_homogeneous.T).T\n",
    "pts_mov_reg = pts_mov_homogeneous_transformed[:, :2] / pts_mov_homogeneous_transformed[:, 2:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ad913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize H so that H[2,2] = 1\n",
    "pts_mov_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b58c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(pts_ref[:, 1], pts_ref[:, 0], marker='x', label='Reference points')\n",
    "plt.scatter(pts_mov[:, 1], pts_mov[:, 0], marker='x', label='Moving points before registration')\n",
    "plt.scatter(pts_mov_reg[:, 1], pts_mov_reg[:, 0], marker='x', label='Registered moving points')\n",
    "plt.legend()\n",
    "plt.xlim(0, all_imgs_r[0].shape[1])\n",
    "plt.ylim(all_imgs_r[0].shape[0], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c27bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import ProjectiveTransform, AffineTransform, warp\n",
    "\n",
    "img_ref = all_imgs_r[0]\n",
    "img_mov = all_imgs_r[1]\n",
    "\n",
    "# apply axis swap (image vs cartesian coordinates)\n",
    "S = np.array([\n",
    "    [0, 1, 0],\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1]\n",
    "])\n",
    "A_img =  S @ A @ S  # transform matrix in image coordinates\n",
    "\n",
    "transform = AffineTransform(matrix=A_img) if transform_type == 'affine' else ProjectiveTransform(matrix=A_img)\n",
    "\n",
    "img_mov_reg = warp(img_mov, inverse_map=transform.inverse, output_shape=img_ref.shape)\n",
    "\n",
    "# now plot rgb overlay of reference and registered moving image\n",
    "img_overlay = np.zeros((all_imgs_r[0].shape[0], all_imgs_r[0].shape[1], 3), dtype=np.float32)\n",
    "# img_overlay[..., 0] = img_ref/ np.max(img_ref)  # red channel - reference\n",
    "# img_overlay[..., 1] = img_mov_reg / np.max(img_mov_reg)  # green channel - registered moving\n",
    "# same as above but with applying percentile saturation\n",
    "img_overlay[..., 1] = np.clip(img_ref, 0, np.percentile(img_ref, sat_perc)) / np.percentile(img_ref, sat_perc)  # red channel - reference\n",
    "img_overlay[..., 0] = np.clip(img_mov_reg, 0, np.percentile(img_mov_reg, sat_perc)) / np.percentile(img_mov_reg, sat_perc)  # green channel - registered moving\n",
    "plt.figure(dpi=500, figsize=(8, 8))\n",
    "plt.imshow(img_overlay)\n",
    "plt.title('Overlay of reference (green) and registered moving (red) images')\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4208059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellpose import models\n",
    "from tqdm import tqdm\n",
    "\n",
    "# mn_image is your 512×512 numpy array (dtype float or uint8 etc.)\n",
    "\n",
    "# 1. instantiate the model (use GPU if available)\n",
    "model = models.CellposeModel(gpu=True, pretrained_model='cpsam')\n",
    "\n",
    "all_mask0 = []\n",
    "all_num_labels = []\n",
    "\n",
    "for img in tqdm(all_imgs_r):\n",
    "    # 2. Cellpose expects a list of images, possibly with channel dimension(s).\n",
    "    #    If your image is single-channel, wrap it in a list.\n",
    "    imgs = [img]  # list of one image # TODO \n",
    "\n",
    "    # 3. Run segmentation\n",
    "    #    You can tune e.g. flow_threshold, cellprob_threshold, diameter, etc.\n",
    "    masks, flows, styles = model.eval(\n",
    "        imgs,\n",
    "        diameter=None,\n",
    "        flow_threshold=0.4,\n",
    "        cellprob_threshold=0.0,\n",
    "        resample=True,\n",
    "        normalize=True,\n",
    "        # other options you might want to adjust:\n",
    "        # invert=False, rescale=None, augment=False, tile_overlap=0.1, min_size=15\n",
    "    )\n",
    "\n",
    "    # 4. masks[0] is the segmentation mask for your image\n",
    "    mask0 = masks[0]\n",
    "\n",
    "    # Example: inspect number of objects\n",
    "    num_labels = mask0.max()\n",
    "    print(\"Detected\", num_labels, \"objects\")\n",
    "\n",
    "    all_mask0.append(mask0)\n",
    "    all_num_labels.append(num_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a29c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the segmentation with \n",
    "def plot_segmentation_overlay(all_img, all_mask):\n",
    "    fig, axs = plt.subplots(1, len(all_img), figsize=(8*len(all_img), 8), dpi=500)\n",
    "    if len(all_img) == 1:\n",
    "        axs = [axs]  # make it iterable\n",
    "    for i, ax in enumerate(axs):\n",
    "        # get random colors for each label\n",
    "        ax.imshow(all_img[i], cmap='gray', vmin=0, vmax=np.percentile(all_img[i], sat_perc))\n",
    "        # now plot contours using contour plot\n",
    "        ax.contour(all_mask[i], colors='C0', linewidths=0.5)\n",
    "        ax.set_title(f'Image {i} with segmentation contours')\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79be4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation_overlay(all_imgs_r, all_mask0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1487ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get centroids of ROIs and track them by doing registration and matching\n",
    "from scipy.ndimage import center_of_mass\n",
    "all_cent = []\n",
    "for mask0 in all_mask0:\n",
    "    num_labels = mask0.max()\n",
    "    centroids = []\n",
    "    for label in range(1, num_labels+1):\n",
    "        centroid = center_of_mass(mask0 == label)\n",
    "        centroids.append(centroid)\n",
    "    all_cent.append(np.array(centroids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f7765",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import cKDTree\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeca876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now show plot with lines connecting matched area\n",
    "def plot_area_comparison(areas_ref, areas_mov, norm=False):\n",
    "    if norm == True:\n",
    "        # normalise each value based on the value in reference\n",
    "        areas_mov = areas_mov / areas_ref\n",
    "        areas_ref = areas_ref / areas_ref\n",
    "\n",
    "    plt.figure(figsize=(2, 3), dpi=500)\n",
    "    plt.scatter(np.zeros_like(areas_ref), areas_ref, s=1, c='C0', label='Reference areas')\n",
    "    plt.scatter(np.ones_like(areas_mov), areas_mov, s=1, c='C2', label='Moving areas')\n",
    "    for k in range(len(areas_ref)):\n",
    "        plt.plot([0, 1], [areas_ref[k], areas_mov[k]], 'grey', linewidth=0.5, alpha=0.3)\n",
    "    plt.xticks([0, 1], ['Reference', 'Moving'])\n",
    "    plt.ylabel('Area (µm²)') if norm == False else plt.ylabel('Normalised area (au)')\n",
    "    plt.title('Areas for matched cells')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e426d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # now implement the tracking pipeline\n",
    "# i = 5\n",
    "# j = i+1\n",
    "match_threshold = 10.0  # pixels\n",
    "show_plot = False\n",
    "\n",
    "px_size = 0.7 # um per pixel\n",
    "\n",
    "# now make a variable to keep track of the trajectories (indices across frames)\n",
    "\n",
    "for i in range(len(all_imgs_r)-1):\n",
    "    j = i+1\n",
    "\n",
    "    # compute affine for matched keypoints\n",
    "    pts_ref = all_keypoints_r[i]\n",
    "    pts_mov = all_keypoints_r[j]\n",
    "    pts_ref_homogeneous = points_to_homogeneous(pts_ref)\n",
    "    pts_mov_homogeneous = points_to_homogeneous(pts_mov)\n",
    "\n",
    "    # compute transform\n",
    "    A = get_affine(pts_mov_homogeneous, pts_ref_homogeneous)\n",
    "\n",
    "    # apply to centroids \n",
    "    cent_ref = all_cent[i]\n",
    "    cent_mov = all_cent[j]\n",
    "\n",
    "    cent_mov_homogeneous = points_to_homogeneous(cent_mov)\n",
    "    cent_mov_homogeneous_transformed = (A @ cent_mov_homogeneous.T).T\n",
    "    cent_mov_reg = cent_mov_homogeneous_transformed[:, :2] / cent_mov_homogeneous_transformed[:, 2:3]\n",
    "\n",
    "    # calculate pairwise distances and use linear sum assignment to find matches\n",
    "    dist_mat = np.linalg.norm(cent_ref[:, np.newaxis, :] - cent_mov_reg[np.newaxis, :, :], axis=2)\n",
    "    row_ind, col_ind = linear_sum_assignment(dist_mat)\n",
    "    # filter matches by threshold\n",
    "    valid_matches = dist_mat[row_ind, col_ind] < match_threshold\n",
    "    matched_ref_indices = row_ind[valid_matches]\n",
    "    matched_mov_indices = col_ind[valid_matches]\n",
    "\n",
    "    ##### AREAS CALCULATION\n",
    "        # now calculate for the matched cells the area of the ROIs\n",
    "    areas_ref = []\n",
    "    areas_mov = []\n",
    "    for idx in matched_ref_indices:\n",
    "        mask = all_mask0[i] == (idx + 1)  # labels start from 1\n",
    "        area = np.sum(mask)\n",
    "        areas_ref.append(area)\n",
    "    for idx in matched_mov_indices:\n",
    "        mask = all_mask0[j] == (idx + 1)  # labels start from 1\n",
    "        area = np.sum(mask)\n",
    "        areas_mov.append(area)\n",
    "    areas_ref = np.array(areas_ref)\n",
    "    areas_mov = np.array(areas_mov)\n",
    "\n",
    "    # now calculate area in um^2\n",
    "    areas_ref = areas_ref * (px_size ** 2)\n",
    "    areas_mov = areas_mov * (px_size ** 2)\n",
    "\n",
    "    ##### TRAJECTORY ACROSS ALL DAYS CALCULATION\n",
    "\n",
    "    if i == 0:\n",
    "        n_match_d0 = len(matched_ref_indices)\n",
    "        traj_indices = np.nan * np.ones((n_match_d0, len(all_imgs_r)))\n",
    "        traj_indices[:, 0] = matched_ref_indices\n",
    "        traj_indices[:, 1] = matched_mov_indices\n",
    "        traj_areas = np.nan * np.ones((n_match_d0, len(all_imgs_r)))\n",
    "        traj_areas[:, 0] = areas_ref\n",
    "        traj_areas[:, 1] = areas_mov\n",
    "    else:\n",
    "        # now check which of the matched_ref_indices are in the previous matched_mov_indices\n",
    "        prev_matched_mov_indices = traj_indices[:, i]\n",
    "        # now find these and add entries tro traj_indices\n",
    "        for k in range(len(matched_ref_indices)):\n",
    "            ref_idx = matched_ref_indices[k]\n",
    "            mov_idx = matched_mov_indices[k]\n",
    "            if ref_idx in prev_matched_mov_indices:\n",
    "                # find the row in traj_indices where prev matched mov index is located\n",
    "                row_idx = np.where(traj_indices[:, i] == ref_idx)[0][0]\n",
    "                traj_indices[row_idx, j] = mov_idx\n",
    "                traj_areas[row_idx, j] = areas_mov[k]\n",
    "\n",
    "\n",
    "########## PLOTTING\n",
    "\n",
    "    if show_plot:\n",
    "        # scatter before and after\n",
    "        plt.figure(figsize=(8, 8), dpi=500)\n",
    "        plt.scatter(cent_ref[:, 1], cent_ref[:, 0], marker='x', c='C0', s=10, alpha=0.5, label='Reference centroids')\n",
    "        # plt.scatter(cent_mov[:, 1], cent_mov[:, 0], marker='x', c='C1', s=10, alpha=0.5, label='Moving centroids before registration')\n",
    "        plt.scatter(cent_mov_reg[:, 1], cent_mov_reg[:, 0], marker='x', c='C2', s=10, alpha=0.5, label='Registered moving centroids')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, all_imgs_r[0].shape[1])\n",
    "        plt.ylim(all_imgs_r[0].shape[0], 0)\n",
    "\n",
    "        # now plot matches in without alpha and non-matches with alpha=0.3\n",
    "        plt.figure(figsize=(8, 8), dpi=500)\n",
    "        plt.scatter(cent_ref[:, 1], cent_ref[:, 0], marker='x', c='C0', s=10, alpha=0.3, label='Reference centroids')\n",
    "        plt.scatter(cent_mov_reg[:, 1], cent_mov_reg[:, 0], marker='x', c='C2',s=10, alpha=0.3, label='Registered moving centroids')\n",
    "        plt.scatter(cent_ref[matched_ref_indices, 1], cent_ref[matched_ref_indices, 0], c='C0', marker='x', s=10, alpha=1.0, label='Matched reference centroids')\n",
    "        plt.scatter(cent_mov_reg[matched_mov_indices, 1], cent_mov_reg[matched_mov_indices, 0], c='C2', marker='x', s=10, alpha=1.0, label='Matched registered moving centroids')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, all_imgs_r[0].shape[1])\n",
    "        plt.ylim(all_imgs_r[0].shape[0], 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        fig, axs = plt.subplots(2, 1, figsize=(6, 8), dpi=500)\n",
    "        # make sure both histograms use the same bins\n",
    "        bins = np.linspace(min(min(areas_ref), min(areas_mov)), max(max(areas_ref), max(areas_mov)), 20)\n",
    "        axs[0].hist(areas_ref, bins=bins, alpha=0.7, label='Reference areas', color='C0')\n",
    "        axs[0].hist(areas_mov, bins=bins, alpha=0.7, label='Moving areas', color='C2')\n",
    "        axs[0].set_title('Histogram of ROI areas (matched cells)')\n",
    "        axs[0].set_xlabel('Area (µm²)')\n",
    "        axs[0].set_ylabel('Count')\n",
    "        axs[0].legend()\n",
    "\n",
    "        bins = np.linspace(min(areas_mov - areas_ref), max(areas_mov - areas_ref), 20)\n",
    "        axs[1].hist(areas_mov - areas_ref, bins=bins, alpha=0.7, color='C3')\n",
    "        axs[1].axvline(0, color='k', linestyle='--')\n",
    "        axs[1].set_title('Histogram of ROI area differences (Moving - Reference)')\n",
    "        axs[1].set_xlabel('Area difference (µm²)')\n",
    "        axs[1].set_ylabel('Count')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plot_area_comparison(areas_ref, areas_mov)\n",
    "        # now plot normalised to reference\n",
    "        plot_area_comparison(areas_ref, areas_mov, norm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b2f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make traj_indices a numpy array\n",
    "plt.matshow(traj_indices, cmap='viridis', aspect='auto')\n",
    "plt.matshow(traj_areas, cmap='viridis', aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb0d323",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the areas that are there for all days\n",
    "plt.figure(figsize=(4, 8), dpi=300)\n",
    "valid_area_mask = ~np.isnan(traj_areas).any(axis=1)\n",
    "traj_areas_valid = traj_areas[valid_area_mask, :]\n",
    "\n",
    "for i in range(traj_areas_valid.shape[0]):\n",
    "    plt.plot(traj_areas_valid[i, :], alpha=0.5, color=f'C{i}', linewidth=0.5)\n",
    "    plt.scatter(np.arange(traj_areas_valid.shape[1]), traj_areas_valid[i, :], s=3, color=f'C{i}')\n",
    "plt.xlabel('Day index')\n",
    "plt.ylabel('Area (µm²)')\n",
    "plt.title('Cell area trajectories for cells tracked across all days')   \n",
    "plt.show()\n",
    "\n",
    "# now calculate correlation coefficient and linear fit \n",
    "x_traj = np.arange(traj_areas_valid.shape[1])\n",
    "x_stack = np.tile(x_traj, (traj_areas_valid.shape[0], 1))\n",
    "x = x_stack.flatten()\n",
    "y = traj_areas_valid.flatten()\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r_value, p_value, std_err = linregress(x, y)\n",
    "print(f'Linear fit slope: {slope}, intercept: {intercept}, R^2: {r_value**2}, p-value: {p_value}')\n",
    "\n",
    "r = np.corrcoef(x, y)[0, 1]\n",
    "print(f'Correlation coefficient: {r}')\n",
    "\n",
    "plt.figure(figsize=(4, 8), dpi=300)\n",
    "plt.scatter(x+np.random.normal(scale=0.05, size=y.shape), y, s=3, alpha=1)\n",
    "plt.plot(x, intercept + slope * x, 'k--', alpha=0.5, label='Fitted line')\n",
    "plt.xlabel('Day index')\n",
    "plt.ylabel('Area (µm²)')\n",
    "plt.title(f'Area vs Day index for tracked cells (R={r:.2f})')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "norm_areas_mat = traj_areas_valid / traj_areas_valid[:, 0:1]\n",
    "y_norm = norm_areas_mat.flatten()\n",
    "\n",
    "slope_norm, intercept_norm, r_value_norm, p_value_norm, std_err_norm = linregress(x, y_norm)\n",
    "print(f'Normalised Linear fit slope: {slope_norm}, intercept: {intercept_norm}, R^2: {r_value_norm**2}, p-value: {p_value_norm}')\n",
    "\n",
    "r= np.corrcoef(x, y_norm)[0, 1]\n",
    "print(f'Normalised Correlation coefficient: {r}')\n",
    "plt.figure(figsize=(4, 8), dpi=300)\n",
    "plt.scatter(x+np.random.normal(scale=0.05, size=y_norm.shape), y_norm, s=3, alpha=1)\n",
    "plt.plot(x, intercept_norm + slope_norm * x, 'k--', alpha=0.5, label='Fitted line')\n",
    "plt.xlabel('Day index')\n",
    "plt.ylabel('Normalised area (au)')\n",
    "plt.title(f'Normalised Area vs Day index for tracked cells (R={r:.2f})')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# now normalised to first day\n",
    "plt.figure(figsize=(4, 8), dpi=300)\n",
    "for i in range(traj_areas_valid.shape[0]):\n",
    "    norm_areas = traj_areas_valid[i, :] / traj_areas_valid[i, 0]\n",
    "    plt.plot(norm_areas, alpha=0.5, color=f'C{i}', linewidth=0.5)\n",
    "    plt.scatter(np.arange(traj_areas_valid.shape[1]), norm_areas, s=3, color=f'C{i}')\n",
    "plt.xlabel('Day index')\n",
    "plt.ylabel('Normalised area (au)')\n",
    "plt.title('Normalised cell area trajectories for cells tracked across all days')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db912968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get the areas that are there for all days\n",
    "plt.figure(figsize=(4, 8))\n",
    "valid_area_mask = ~np.isnan(traj_areas).any(axis=1)\n",
    "traj_areas_valid = traj_areas[valid_area_mask, :]\n",
    "\n",
    "for i in range(traj_areas_valid.shape[0]):\n",
    "    plt.plot(traj_areas_valid[i, :], '-o', alpha=0.5)\n",
    "plt.xlabel('Day index')\n",
    "plt.ylabel('Area (µm²)')\n",
    "plt.title('Cell area trajectories for cells tracked across all days')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde72a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
