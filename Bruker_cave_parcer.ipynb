{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find and parce the .xml files: main and MarkPoints. In this example picture they are the last and the first files, respectively. \n",
    "\n",
    "![alt text](image-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using xml library, parce the file.\n",
    "\n",
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_raw'\n",
    "experimenter = 'calibration'\n",
    "mouse = 'calibration_sb_mouse_fov0'\n",
    "tseries = 'TSeries-10032023-1822-003'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder to find the .xml files:\n",
    "\n",
    "folder_path = os.path.join(data_dir, experimenter, mouse, tseries)\n",
    "#folder_path = '/Volumes/64g/ani73/References/'\n",
    "\n",
    "folder_path = folder_path + '/'\n",
    "tseries_main_xml_path = glob(folder_path + '*[0-9].xml')[0]\n",
    "print(f'Found main .xml file: {tseries_main_xml_path}')\n",
    "root = ET.parse(tseries_main_xml_path)\n",
    "frame_times = [float(i.get('relativeTime')) for i in root.findall('.//Frame')]\n",
    "\n",
    "mark_points_path = glob(folder_path + \"*MarkPoints.xml\")[0]\n",
    "print(f'Found MarkPoints.xml file: {mark_points_path}')\n",
    "root = ET.parse(mark_points_path)\n",
    "\n",
    "stim_start_list = []\n",
    "stim_end_list = []\n",
    "points_list = []\n",
    "coord_x_list = []\n",
    "coord_y_list = []\n",
    "\n",
    "time = 0\n",
    "\n",
    "for series in root.findall('.'):\n",
    "    iter_n = int(series.get('Iterations'))\n",
    "    iter_delay = float(series.get('IterationDelay'))\n",
    "    for iteration_i in range(iter_n):\n",
    "        for mark_point_el in series.findall('./'):\n",
    "            repetition_n = int(mark_point_el.get('Repetitions'))\n",
    "            #Assuming only one PVGalvoPointElement in PVMarkPointElement\n",
    "            init_delay = float(mark_point_el.find('./').get('InitialDelay'))\n",
    "            time += init_delay\n",
    "            for repetition_i in range(repetition_n):\n",
    "                for galvo_point_el in mark_point_el.findall('./'):\n",
    "                    inter_point_delay = float(galvo_point_el.get('InterPointDelay'))\n",
    "                    duration = float(galvo_point_el.get('Duration'))\n",
    "                    points = galvo_point_el.get('Points') \n",
    "                    \n",
    "                    # Assuming there's only one Point per PVGalvoPointElement\n",
    "                    point_x = float(galvo_point_el.find('./').get('X'))\n",
    "                    point_y = float(galvo_point_el.find('./').get('Y'))\n",
    "\n",
    "                    #stim_start_i = (iteration_i * iter_delay) + (repetition_i * inter_point_delay) + ((repetition_i) * duration) + overall_delay\n",
    "                    #stim_end_i = (iteration_i * iter_delay) + (repetition_i * inter_point_delay) + ((repetition_i+1) * duration) + overall_delay\n",
    "\n",
    "                    stim_start_i = time\n",
    "                    time += duration\n",
    "                    stim_end_i = time\n",
    "                    \n",
    "                    # Comparing with the frametime of the last recorded frame\n",
    "                    if stim_start_i <= frame_times[-1]*1000:\n",
    "                        stim_start_list.append(stim_start_i)\n",
    "                        stim_end_list.append(stim_end_i)\n",
    "                        points_list.append(points)\n",
    "                        coord_x_list.append(point_x)\n",
    "                        coord_y_list.append(point_y)\n",
    "                        #overall_delay += stim_end_list[-1] - stim_start_list[-1]\n",
    "                    else:\n",
    "                        # If the recording was stopped earlier then all the planned stimulation, we break\n",
    "                        break\n",
    "                    \n",
    "                    if repetition_i+1 != repetition_n:\n",
    "                        time += inter_point_delay\n",
    "\n",
    "        time += iter_delay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a dictionary that contains all the stimulation-related information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_dict = {'stim_points_name': points_list,\n",
    "             'stim_coord_x': coord_x_list,\n",
    "             'stim_coord_y': coord_y_list,\n",
    "                'stim_start': stim_start_list,\n",
    "                'stim_start_fr': np.searchsorted(frame_times, np.array(stim_start_list)/1000), # /1000 to convert ms to s\n",
    "                'stim_end': stim_end_list,\n",
    "                'stim_end_fr': np.searchsorted(frame_times, np.array(stim_end_list)/1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stim_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Stim aritfact removal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we select the folder that contains the results of suite2p analysis and extract the values. \n",
    "Written for single-plane recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "#s2p_folder_path = '/Volumes/64g/TSeries-02022024-1633-006/suite2p/plane0/'\n",
    "#s2p_folder_path = '/Volumes/64g/ani73/suite2p/plane0/'\n",
    "s2p_folder_path = '/Users/anaconda/Desktop/to_write_parcer/TSeries-02022024-1633-006/suite2p/plane0'\n",
    "\n",
    "stat_npy = np.load(s2p_folder_path + '/stat.npy', allow_pickle=True)\n",
    "iscell_npy = np.load(s2p_folder_path + '/iscell.npy')\n",
    "ops_npy = np.load(s2p_folder_path + '/ops.npy', allow_pickle=True)[()]\n",
    "F = np.load(s2p_folder_path + '/F.npy')\n",
    "\n",
    "X_size = ops_npy['Lx']\n",
    "Y_size = ops_npy['Ly']\n",
    "\n",
    "X_all = []\n",
    "Y_all = []\n",
    "\n",
    "for i in range(stat_npy.shape[0]):\n",
    "    X_all.append(np.mean(stat_npy[i]['xpix']))\n",
    "    Y_all.append(np.mean(stat_npy[i]['ypix']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method to find the closest suite2p-detected cell for each pair of coordinates from the MarkPoints file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_cells(stim_coord_x, stim_coord_y, X_all, Y_all, n_closest_cells = 5, iscell_only = False):\n",
    "\n",
    "  def distance(x1, y1, x2, y2):\n",
    "    return np.sqrt(((x1 - x2) ** 2) + ((y1 - y2) ** 2))\n",
    "\n",
    "  if stat_npy.shape[0] > n_closest_cells:\n",
    "\n",
    "    distances = []\n",
    "    for j, (x, y) in enumerate(zip(X_all, Y_all)):\n",
    "      dist = distance(stim_coord_x*X_size, stim_coord_y*Y_size, x, y)\n",
    "      distances.append((dist, j))  # Store distance and index of cell\n",
    "\n",
    "    #print(distances)\n",
    "\n",
    "    closest_indices = []\n",
    "    for dist, j in distances:\n",
    "      heapq.heappush(closest_indices, (dist, j))\n",
    "      \n",
    "      # Get top 5 valid closest cells using nlargest\n",
    "    \n",
    "    if iscell_only:\n",
    "      closest_cells = [(j, round(i,1)) for i, j in heapq.nsmallest(len(closest_indices), closest_indices, key=lambda x: x[0]) if iscell_npy[j][0] == 1][:n_closest_cells]\n",
    "    else:\n",
    "      closest_cells = [(j, round(i,1)) for i, j in heapq.nsmallest(n_closest_cells, closest_indices, key=lambda x: x[0])]\n",
    "      \n",
    "      return closest_cells\n",
    "  else:\n",
    "    print(f'You have less then {n_closest_cells+1} cell')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the closest cells and adding tuples (closest cell number, distance) to the dictionary. The number of added tuples is defined by variable n_closest_cells = 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_s2p_cells = []\n",
    "for name, x, y in zip(stim_dict['stim_points_name'], stim_dict['stim_coord_x'], stim_dict['stim_coord_y']):\n",
    "    print(name)\n",
    "    print(find_closest_cells(x,y, X_all, Y_all))\n",
    "    closest_s2p_cells.append(find_closest_cells(x,y, X_all, Y_all))\n",
    "\n",
    "stim_dict['closest_s2p_cell(n_distance)'] = closest_s2p_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: write a convinient method to select the stimulated cell manually. Make an empty array for manual input. If it's empty, just use the closest (maybe also valid?) cell.\n",
    "# Also, account for the cases where the time between the stimulatons is shorter then the timewindow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Stim cells:\n",
    "\n",
    "# go throught each stim_start and stim_cell_n_i[0][0]\n",
    "# redo methods to retrive the psth for all cells but single stim\n",
    "# then do the tests and form the array that goes to the output table\n",
    "\n",
    "# Isolating raw flourescence values that correspond to a specific stimulation frame\n",
    "# Input: Stimulation frame number stim_fr_i, psth size (matematically: [-diapazone, diapazone]): diapazone\n",
    "# Output: Flourescence traces for all cells before the stim ([stim_fr_i-diapazone, stim_fr_i]):psth_before, \n",
    "#         Flourescence traces for all cells after the stim ([stim_fr_i, stim_fr_i+diapazone]):psth_after \n",
    "\n",
    "def extract_psth(stim_fr_i, diapazone=30):\n",
    "    psth_before = np.zeros((F.shape[0], diapazone))\n",
    "    psth_after = np.zeros((F.shape[0], diapazone))\n",
    "    for cell_i in range(F.shape[0]):\n",
    "        psth_before[cell_i] = F[cell_i][stim_fr_i-diapazone:stim_fr_i]\n",
    "        psth_after[cell_i] = F[cell_i][stim_fr_i:stim_fr_i+diapazone]\n",
    "\n",
    "    return psth_before, psth_after\n",
    "\n",
    "stim_cell_response_list = []\n",
    "\n",
    "# Counting the number of values in an array (arr) that surpass the threshold (thr) CONSEQUTEVLY. Returns the maximum number of consequtive values.\n",
    "def conseq_over_thr(arr, thr) -> int:\n",
    "    if thr > 0:\n",
    "        binarized = np.where(arr >= thr, 1, 0)\n",
    "    else:\n",
    "        binarized = np.where(arr <= thr, 1, 0)\n",
    "    max_c_n = 0\n",
    "    c_n = 0\n",
    "    for i in binarized:\n",
    "        if i == 1:\n",
    "            c_n += 1\n",
    "            if c_n > max_c_n:\n",
    "                max_c_n = c_n\n",
    "        else:\n",
    "            c_n = 0\n",
    "    return max_c_n\n",
    "\n",
    "\n",
    "def plot_psth(array1, array2, text, diapazone):\n",
    "    # Generate x values for each array\n",
    "    #x_values1 = np.arange(-diapazone, 0)\n",
    "    #x_values2 = np.arange(0, diapazone)\n",
    "    x_val = np.arange(-diapazone, diapazone)\n",
    "    y_val = [*array1, *array2]\n",
    "    # Plot the data\n",
    "    #plt.plot(x_values1, array1, label='Pre-stim')\n",
    "    #plt.plot(x_values2, array2, label='Post-stim')\n",
    "    plt.plot(x_val, y_val)\n",
    "    plt.suptitle(text)\n",
    "    plt.vlines(0, min(y_val) - 3, max(y_val) + 3, 'r', 'dashed')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Setting the cosecutive treshold and diapazone for \n",
    "conseq = 5\n",
    "DIAPAZONE = 10\n",
    "\n",
    "stim_indirect_response_pos = []\n",
    "stim_indirect_response_neg = []\n",
    "\n",
    "for stim_start_fr_i, stim_cell_n_i in zip(stim_dict['stim_start_fr'], stim_dict['closest_s2p_cell(n_distance)']):\n",
    "\n",
    "    if stim_start_fr_i + DIAPAZONE < F.shape[1]: # Checking that there's enough frames after stim to make psth\n",
    "\n",
    "        psth_before, psth_after = extract_psth(stim_start_fr_i, DIAPAZONE)\n",
    "        stim_indirect_response_pos_i = []\n",
    "        stim_indirect_response_neg_i = []\n",
    "        for cell_i in range(F.shape[0]):\n",
    "            if cell_i == stim_cell_n_i[0][0]:\n",
    "                if ttest_rel(psth_before[cell_i], psth_after[cell_i])[1] <= 0.05:\n",
    "                    stim_cell_response_list.append(1)\n",
    "                else:\n",
    "                    stim_cell_response_list.append(0)\n",
    "                plot_psth(psth_before[cell_i], psth_after[cell_i], ttest_rel(psth_before[cell_i], psth_after[cell_i]), DIAPAZONE)\n",
    "\n",
    "            else:\n",
    "                if iscell_npy[cell_i][0] == 1:\n",
    "                    baseAvg = np.mean(psth_before[cell_i])\n",
    "                    baseStd = np.std(psth_before[cell_i])\n",
    "                    #z_score_before = (psth_before - baseAvg) / baseStd\n",
    "                    z_score_after = (psth_after[cell_i] - baseAvg) / baseStd\n",
    "                    \n",
    "                    if conseq_over_thr(z_score_after, 1.96) >= conseq:\n",
    "                        stim_indirect_response_pos_i.append(cell_i)\n",
    "                    if conseq_over_thr(z_score_after, -1.65) >= conseq:\n",
    "                        stim_indirect_response_neg_i.append(cell_i)\n",
    "\n",
    "    else:\n",
    "        stim_cell_response_list.append(None)\n",
    "\n",
    "    stim_indirect_response_pos.append(stim_indirect_response_pos_i)\n",
    "    stim_indirect_response_neg.append(stim_indirect_response_neg_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_dict['stim_cell_response'] = stim_cell_response_list\n",
    "stim_dict['indir_pos_response'] = stim_indirect_response_pos\n",
    "stim_dict['indir_neg_response'] = stim_indirect_response_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame.from_dict(stim_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ChatGPT 3.5 code - neat but slower\n",
    "\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_psth(F, stim_fr_i, diapazone=30):\n",
    "    psth_before = F[:, stim_fr_i - diapazone:stim_fr_i]\n",
    "    psth_after = F[:, stim_fr_i + 1:stim_fr_i + diapazone + 1]\n",
    "    return psth_before, psth_after\n",
    "\n",
    "def conseq_over_thr(arr, thr):\n",
    "    binarized = np.where((thr > 0) & (arr >= thr) | (thr <= 0) & (arr <= thr), 1, 0)\n",
    "    max_c_n = 0\n",
    "    c_n = 0\n",
    "    for i in binarized:\n",
    "        c_n = c_n + 1 if i == 1 else 0\n",
    "        max_c_n = max(max_c_n, c_n)\n",
    "    return max_c_n\n",
    "\n",
    "conseq = 3\n",
    "stim_cell_response_list = []\n",
    "stim_indirect_response_pos = []\n",
    "stim_indirect_response_neg = []\n",
    "\n",
    "for stim_start_fr_i, stim_cell_n_i in zip(stim_dict['stim_start_fr'], stim_dict['closest_s2p_cell(n_distance)']):\n",
    "    psth_before, psth_after = extract_psth(F, stim_start_fr_i, 30)\n",
    "    stim_indirect_response_pos_i = [cell_i for cell_i in range(F.shape[0]) if cell_i != stim_cell_n_i[0][0] and conseq_over_thr((psth_after[cell_i] - np.mean(psth_before[cell_i])) / np.std(psth_before[cell_i]), 1.96) >= conseq]\n",
    "    stim_indirect_response_neg_i = [cell_i for cell_i in range(F.shape[0]) if cell_i != stim_cell_n_i[0][0] and conseq_over_thr((psth_after[cell_i] - np.mean(psth_before[cell_i])) / np.std(psth_before[cell_i]), -1.65) >= conseq]\n",
    "\n",
    "    stim_indirect_response_pos.extend(stim_indirect_response_pos_i)\n",
    "    stim_indirect_response_neg.extend(stim_indirect_response_neg_i)\n",
    "\n",
    "    if ttest_rel(psth_before[stim_cell_n_i[0][0]], psth_after[stim_cell_n_i[0][0]])[1] >= 0.90:\n",
    "        stim_cell_response_list.append(1)\n",
    "    else:\n",
    "        stim_cell_response_list.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sainty check - drawing the stimulated cells on the FOV shot.\n",
    "\n",
    "from PIL import ImageDraw, Image, ImageFont\n",
    "\n",
    "def extract_values(xml_data):\n",
    "  \"\"\"\n",
    "  Extracts X, Y, and SpiralWidth values from a provided XML string.\n",
    "\n",
    "  Args:\n",
    "    xml_data: A string containing the XML data.\n",
    "\n",
    "  Returns:\n",
    "    A list of dictionaries, where each dictionary contains the extracted values\n",
    "    for a single <Point> element.\n",
    "  \"\"\"\n",
    "\n",
    "  root = ET.parse(xml_data)\n",
    "  values = []\n",
    "\n",
    "  for point in root.findall(\".//Point\"):\n",
    "    values.append({\n",
    "      \"X\": float(point.get(\"X\")),\n",
    "      \"Y\": float(point.get(\"Y\")),\n",
    "      \"SpiralWidth\": float(point.get(\"SpiralWidth\")),\n",
    "    })\n",
    "\n",
    "  return values\n",
    "\n",
    "extracted_values = extract_values('/Volumes/2TB_VIRUS/ani76_2023-02-12/TSeries-02122024-1600-002/References/TSeries-02122024-1600-002_Cycle00001_MarkPoints.xml')\n",
    "\n",
    "print(extracted_values)\n",
    "\n",
    "\n",
    "# Specify image path and circle diameter\n",
    "image_path = \"/Volumes/2TB_VIRUS/ani76_2023-02-12/TSeries-02122024-1600-002/Test.png\"\n",
    "\n",
    "# Open the image\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Create an ImageDraw object for drawing\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Get image dimensions\n",
    "width, height = img.size\n",
    "\n",
    "def draw_circle_with_text(x, y, diameter, text=None):\n",
    "    # Convert relative coordinates to absolute pixels\n",
    "    center_x = int(x * width)\n",
    "    center_y = int(y * height)\n",
    "    radius = diameter // 2  # Calculate radius from diameter\n",
    "\n",
    "    # Draw the circle with red color and 2px thickness\n",
    "    draw.ellipse((center_x - radius, center_y - radius, center_x + radius, center_y + radius), outline=(255, 0, 0), width=2, fill='red')\n",
    "\n",
    "    if text:\n",
    "        # Load a font\n",
    "        #font = ImageFont.truetype(\"arial.ttf\", 5)  # Adjust font and size\n",
    "\n",
    "        # Calculate text dimensions\n",
    "        #text_width, text_height = \n",
    "\n",
    "        # Adjust text position relative to circle center\n",
    "        text_x = center_x - 5 // 2\n",
    "        text_y = center_y - 5 // 2\n",
    "\n",
    "        # Draw the text in black color\n",
    "        draw.text((text_x, text_y), text, fill=(255, 0, 0))\n",
    "\n",
    "\n",
    "for n, cicle_dic in enumerate(extracted_values):\n",
    "    # Example usage: Draw circles and text at specific relative coordinates\n",
    "    draw_circle_with_text(cicle_dic['X'], cicle_dic['Y'], cicle_dic['SpiralWidth'], str(n))\n",
    "\n",
    "# Save the modified image\n",
    "img.save(\"/Volumes/2TB_VIRUS/ani76_2023-02-12/TSeries-02122024-1600-002/Test_with_c.png\")\n",
    "\n",
    "\n",
    "print(\"Image saved as modified_image.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
