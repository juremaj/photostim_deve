{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb6bd42",
   "metadata": {},
   "source": [
    "# resp_evoked (quantifying response to evoked activity in a given session)\n",
    "IMPORTANT: Keep this notebook as identical to `resp_photostim.ipynb` as possible.\n",
    "\n",
    "Both scripts do 'trial-based' analysis, where each trial has some start/end time and identity.\n",
    "\n",
    "The identity can be:\n",
    "    1) evoked stimulation trial type (currently they are all the same)\n",
    "    2) photostim stimulation trial type / the identity of the mark point being stimulated\n",
    "\n",
    "The outputs for the 'resp_map-related' part are:\n",
    "    1) 'response map'(s) of the movie field of view for each evoked trial (+summary over trials) - response of network to a particular trial type of evoked activity\n",
    "    2) 'response map'(s) of the movie field of view for each photostim trial (+summary over trials) - response of network to a particular single cell stimulation\n",
    "\n",
    "The outputs for the 'suite2p-related' part are:\n",
    "    1) which cells are responding to a particular evoked stimulation\n",
    "    2) which cells are responding to a particular photostim stimulation (the stimulated cell as well as all other cells)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d530274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel: 2\n",
    "# plane: 0\n",
    "# frame_period: 0.033602476  # metadata-derived frame period for 30Hz acquisition\n",
    "# fov_shape: [512, 512]      # shape of the FOV in pixels\n",
    "\n",
    "# # baseline and response parameters\n",
    "# bsln_n_frames: 10          # baseline window in frames\n",
    "# resp_n_frames: 10          # response window in frames\n",
    "\n",
    "# bsln_sub_type: \"trial_by_trial\"  # 'trial_by_trial' or 'session_wide'\n",
    "\n",
    "# # spatial extent of response\n",
    "# n_dist_bins: 724           # number of distance bins (724 = diagonal of 512x512)\n",
    "\n",
    "# # visualization parameters\n",
    "# n_rows_fov: 4\n",
    "# vlim: 200\n",
    "# txt_shift: [7, 7]\n",
    "# sat_perc_fov: 99.99\n",
    "# peristim_wind: [10, 30]\n",
    "# zoomin_npix: 128\n",
    "\n",
    "# dist_bins_xlim: 362        # 724 // 2\n",
    "# dist_bins_xlim_zoom: 45    # 724 // 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197b6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from photostim_deve.response.io import get_all_tiff_paths, parse_evoked_protocol_csv\n",
    "from photostim_deve.image_analysis.compute import get_resp_imgs\n",
    "from photostim_deve.image_analysis.plot import plot_resp_imgs\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a915b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params (based on resp_photostim_config.yaml)\n",
    "channel = 2\n",
    "plane = 0 \n",
    "frame_period = 0.033602476 # metadata-derived frame period for 30Hz acquisition fov_shape = [512, 512] # shape of the FOV in pixels\n",
    "fov_shape = [512, 512] # shape of the FOV in pixels\n",
    "\n",
    "# suite2p loading paerameters\n",
    "n_planes = 1\n",
    "fs = 1/frame_period\n",
    "act_type = 'dff'\n",
    "\n",
    "# skipping the rest of the parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25067a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsln_dur = 500 # baseline duration in ms (in suite2p response this will also determine the number of frames after res_dur)\n",
    "resp_dur = 2000 # response duration in ms\n",
    "\n",
    "frame_avg_mode = 'median'\n",
    "trial_avg_mode = 'median'\n",
    "\n",
    "plot_debug = False # whether to plot the baseline and response time periods and images for each trial for debugging purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fd299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "subject = 'jm064'\n",
    "session = '2025-11-18_s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c04c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_path = os.path.join('data_proc', 'jm', subject, session)\n",
    "\n",
    "# tiff file paths\n",
    "s2p_path = os.path.join(session_path, 'suite2p', f'plane{plane}')\n",
    "tiff_dir = os.path.join(s2p_path, f'reg_tif_chan{channel}')\n",
    "all_tiff_paths = get_all_tiff_paths(tiff_dir)\n",
    "\n",
    "# stimulation protocol pathsa\n",
    "csv_save_path = os.path.join('data_proc', 'jm', subject, session, 'evoked_protocol.csv')\n",
    "csv_load_path = csv_save_path\n",
    "\n",
    "# output paths\n",
    "output_path = os.path.join(session_path, 'resp_evoked')\n",
    "output_fig_path = os.path.join(output_path, 'fig')\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "if not os.path.exists(output_fig_path):\n",
    "    os.makedirs(output_fig_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182d7383",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times, stim_frames, stim_type = parse_evoked_protocol_csv(session_path, \n",
    "                                                               csv_load_path, \n",
    "                                                               frame_period=frame_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resp_bsln, resp_resp, resp_diff, f_mean = get_resp_imgs(all_tiff_paths, \n",
    "#                                                 stim_frames, \n",
    "#                                                 stim_type, \n",
    "#                                                 frame_avg_mode=frame_avg_mode, \n",
    "#                                                 bsln_dur=bsln_dur, \n",
    "#                                                 resp_dur=resp_dur, \n",
    "#                                                 fov_shape=fov_shape, \n",
    "#                                                 frame_period=frame_period,\n",
    "#                                                 plot_debug=plot_debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c325f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stim_type_plot = 0 # only one stim type in evoked protocol, so just set to 0 for plotting\n",
    "\n",
    "# if trial_avg_mode == 'mean':\n",
    "#     plot_resp_imgs(np.mean(resp_bsln[stim_type_plot], axis=0), np.mean(resp_resp[stim_type_plot], axis=0), np.mean(resp_diff[stim_type_plot], axis=0), j=stim_type_plot, l=0)\n",
    "#     plt.figure(figsize=(6, 6), dpi=300)\n",
    "#     plt.imshow(np.mean(resp_diff[stim_type_plot], axis=0), vmin=-400, vmax=400, cmap='bwr')\n",
    "#     plt.axis('off')\n",
    "\n",
    "# elif trial_avg_mode == 'median':\n",
    "#     plot_resp_imgs(np.median(resp_bsln[stim_type_plot], axis=0), np.median(resp_resp[stim_type_plot], axis=0), np.median(resp_diff[stim_type_plot], axis=0), j=stim_type_plot, l=0)\n",
    "#     plt.figure(figsize=(6, 6), dpi=300)\n",
    "#     plt.imshow(np.median(resp_diff[stim_type_plot], axis=0), vmin=-400, vmax=400, cmap='bwr')\n",
    "#     plt.axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load track2p ROIs (cells tracked across all days from 'fake suite2p')\n",
    "stat = np.load(os.path.join('data_proc/jm/jm064/track2p/matched_suite2p', session, 'suite2p', 'plane0', 'stat.npy'), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6), dpi=300)\n",
    "\n",
    "# if trial_avg_mode == 'mean':\n",
    "#     plt.imshow(np.mean(resp_diff[stim_type_plot], axis=0), vmin=-400, vmax=400, cmap='bwr')\n",
    "# elif trial_avg_mode == 'median':\n",
    "#     plt.imshow(np.median(resp_diff[stim_type_plot], axis=0), vmin=-400, vmax=400, cmap='bwr')\n",
    "\n",
    "# plt.axis('off')\n",
    "# for cell in stat:\n",
    "#     ypix = cell['ypix']\n",
    "#     xpix = cell['xpix']\n",
    "#     contour = np.zeros(fov_shape)\n",
    "#     contour[ypix, xpix] = 1\n",
    "#     plt.contour(contour, colors='k', linewidths=0.1, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8a5dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the intensity for each ROI and plot the distribution of intensities across all ROIs\n",
    "# intensities = []\n",
    "# for cell in stat:\n",
    "#     ypix = cell['ypix']\n",
    "#     xpix = cell['xpix']\n",
    "#     if trial_avg_mode == 'mean':\n",
    "#         intensity = np.mean(resp_diff[stim_type_plot][:, ypix, xpix])\n",
    "#     elif trial_avg_mode == 'median':\n",
    "#         intensity = np.median(resp_diff[stim_type_plot][:, ypix, xpix])\n",
    "#     intensities.append(intensity)\n",
    "\n",
    "# plt.figure(figsize=(8, 2), dpi=300)\n",
    "# plt.hist(intensities, bins=200)\n",
    "# plt.title(f'Distribution of mean intensity in ROIs (trial_avg_mode={trial_avg_mode})')\n",
    "# plt.xlabel('Mean intensity in ROI')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502ead8",
   "metadata": {},
   "source": [
    "# Suite2p responses\n",
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from photostim_deve.response.io import Suite2pLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "iscell_thr = 0 # s2p cell probability (set to 'None' to filter by 'manual curation')\n",
    "resp_s2p_zscore = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060052b",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_path = os.path.join('data_proc/jm/jm064/track2p/matched_suite2p/', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c26b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_loader = Suite2pLoader(ds_path=session_path, fs=fs, act_type=act_type, n_planes=n_planes)\n",
    "n_rois = s2p_loader.get_n_rois()\n",
    "\n",
    "cell_bool, cell_prob = s2p_loader.get_iscell_redcell(mode='iscell', c_idxs=np.arange(n_rois))\n",
    "c_idxs = cell_bool if iscell_thr is None else np.where(cell_prob >= iscell_thr)[0]\n",
    "\n",
    "act = s2p_loader.get_act_session(c_idxs=c_idxs)\n",
    "s2p_idxs = s2p_loader.get_s2p_idxs(c_idxs=c_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94421dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zscore rows\n",
    "def zscore_rows(arr):\n",
    "    \"\"\"Z-score each row of the input array.\"\"\"\n",
    "    mean = np.mean(arr, axis=1, keepdims=True)\n",
    "    std = np.std(arr, axis=1, keepdims=True)\n",
    "    return (arr - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9779de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_5_bin(arr):\n",
    "    \"\"\"Average every 5 columns of the input array.\"\"\"\n",
    "    n_bins = arr.shape[1] // 5\n",
    "    return np.array([arr[:, i*5:(i+1)*5].mean(axis=1) for i in range(n_bins)]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27539f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resp_s2p(act, stim_frames, stim_type, bsln_dur=500, resp_dur=2000, frame_period=0.033602476, plot_debug=False, resp_s2p_zscore=True):\n",
    "    \"\"\" \n",
    "    Extract response traces for each stimulation trial by taking the activity traces in the pre-stim 'baseline', the 'response' and post-stim 'baseline' windows. \n",
    "    Done for each trial type.\n",
    "    \n",
    "    \n",
    "    Parameters: \n",
    "    ---------- \n",
    "    act : np.ndarray\n",
    "        Array of shape (n_neurons, n_frames) containing the activity traces for each neuron.\n",
    "    stim_frames : list \n",
    "        List of frame indices for each stimulation. \n",
    "    stim_type : list \n",
    "        Evoked stim type index corresponding to each stimulation. \n",
    "    bsln_dur : int \n",
    "        Baseline duration in ms. Default is 500 ms. Applies to pre and post-stim baseline windows.\n",
    "    resp_dur : int \n",
    "        Response duration in ms. Default is 2000 ms. \n",
    "    frame_period : float \n",
    "        Exact frame period from metadata used to convert from time to frame index. Default is 0.033602476 (for '30Hz' acquisition). \n",
    "    plot_debug : bool\n",
    "        Whether to generate plots for debugging and sanity checking the synchronisation. Default is False.\n",
    "    resp_s2p_zscore : bool\n",
    "        Whether to z-score the activity traces before extracting the responses. Default is True.\n",
    "        \n",
    "\n",
    "    Returns: \n",
    "    ------- \n",
    "    resp : np.ndarray\n",
    "        Array of shape (n_stim_types, n_stim_repetitions, n_neurons, resp_dur + 2*bsln_dur) containing the time series of the response (resp_dur +/- bsln_dur) of each neuron to each stimulation type on each trial. \n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    n_stim_types = len(np.unique(stim_type))\n",
    "    n_stim_repetitions = len(stim_type) // n_stim_types # assuming equal number of repetitions for each stim type\n",
    "    \n",
    "    bsln_n_frames = int(np.ceil((bsln_dur/1000) / (frame_period))) # convert baseline duration from ms to number of frames\n",
    "    resp_n_frames = int(np.ceil((resp_dur/1000) / (frame_period))) # convert response duration from ms to number of frames\n",
    "\n",
    "    act = zscore_rows(act) if resp_s2p_zscore else act\n",
    "\n",
    "    rand_nrn_idxs_debug = None\n",
    "    if plot_debug:\n",
    "        plt.figure(figsize=(10, 1), dpi=300)\n",
    "        plt.imshow(zscore_rows(act), aspect='auto', cmap='Greys', vmin=0, vmax=1)\n",
    "        for frame in stim_frames:\n",
    "            plt.axvline(frame, color='C0', linestyle='--', linewidth=1)\n",
    "        plt.title('Activity traces with stim frames for debugging synchronisation')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Neuron')\n",
    "\n",
    "        n_rand_nrn = 10\n",
    "        seed = 42\n",
    "        np.random.seed(seed)\n",
    "        rand_nrn_idxs_debug = np.random.choice(act.shape[0], size=n_rand_nrn, replace=False)\n",
    "        plt.figure(figsize=(10, 6), dpi=300)\n",
    "        for i, idx in enumerate(rand_nrn_idxs_debug):\n",
    "            act_proc = avg_5_bin(zscore_rows(act))\n",
    "            plt.plot(act_proc[idx]-i*10, label=f'Neuron {idx}')\n",
    "        for frame in stim_frames:\n",
    "            plt.axvline(frame/5, color='grey', linestyle='--', linewidth=1)\n",
    "        plt.title('Random subset of activity traces with stim frames (6 Hz avg downsampled)')\n",
    "        plt.xlabel('Frame')\n",
    "    \n",
    "    # now get responses\n",
    "    resp = np.zeros((n_stim_types, n_stim_repetitions, act.shape[0], bsln_n_frames*2 + resp_n_frames))\n",
    "\n",
    "    for j in range(n_stim_types):\n",
    "        stim_type_j_frames = stim_frames[stim_type == j] # get the stim frames for the current stim type \n",
    "\n",
    "        for k, stim_frame in enumerate(stim_type_j_frames):\n",
    "            peristim_wind = (stim_frame - bsln_n_frames, \n",
    "                             stim_frame + resp_n_frames + bsln_n_frames)\n",
    "            \n",
    "            resp[j, k] = act[:, peristim_wind[0]:peristim_wind[1]]\n",
    "\n",
    "    return resp, rand_nrn_idxs_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6be3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp, rand_nrn_idxs_debug = get_resp_s2p(act, stim_frames, stim_type, bsln_dur=bsln_dur, resp_dur=resp_dur, frame_period=frame_period, plot_debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748218e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bsln_n_frames = int(np.ceil((bsln_dur/1000) / (frame_period))) # convert baseline duration from ms to number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0062b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Think if to subtract the baseline trial-by-trial (as in the get_resp_imgs function) or to just z-score the activity across the whole session "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42caf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the response traces for a random subset of neurons to check the extracted responses\n",
    "stim_type_plot = 0 # only one stim type in evoked protocol, so just set\n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(10, 3), dpi=300, sharex=True, sharey=True)\n",
    "for i in range(10):\n",
    "    # plot single trials in grey\n",
    "    resp_nrn = resp[stim_type_plot, :, rand_nrn_idxs_debug[i], :]\n",
    "    # subtract baseline\n",
    "    resp_nrn = resp_nrn - np.mean(resp_nrn[:, :bsln_n_frames], axis=1, keepdims=True)\n",
    "    axs[i].plot(resp_nrn.T, color='grey', alpha=0.01)\n",
    "    # plot mean across trials in color\n",
    "    axs[i].plot(np.median(resp_nrn, axis=0), color=f'C{i}', label=f'Neuron {rand_nrn_idxs_debug[i]}')\n",
    "    axs[i].axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now plot the response traces for a random subset of neurons to check the extracted responses (single trial, using bwr)\n",
    "stim_type_plot = 0 # only one stim type in evoked protocol, so just set\n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(10, 1), dpi=600, sharex=True, sharey=True)\n",
    "for i in range(10):\n",
    "    # plot single trials in grey\n",
    "    resp_nrn = resp[stim_type_plot, :, rand_nrn_idxs_debug[i], :]\n",
    "    # subtract baseline\n",
    "    resp_nrn = resp_nrn #- np.mean(resp_nrn[:, :bsln_n_frames], axis=1, keepdims=True)\n",
    "    axs[i].imshow(resp_nrn, aspect='auto', cmap='bwr', vmin=-5, vmax=5)\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee43b447",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp.shape)\n",
    "resp_mean = np.mean(resp, axis=(0,1)) # average across trials for each stim type\n",
    "resp_med = np.median(resp, axis=(0,1)) # average across trials for each stim type\n",
    "resp_std = np.std(resp, axis=(0,1)) # average across trials for each stim type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_dict = {\n",
    "    's2p_idxs': s2p_idxs,\n",
    "    'resp': resp,\n",
    "    'resp_mean': resp_mean,\n",
    "    'resp_med': resp_med,\n",
    "    'resp_std': resp_std,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b847aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e7182",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(output_path, 'resp_evoked.npy'), exp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa11971e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4c9dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inhideve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
