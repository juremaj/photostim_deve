{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fa30f23",
   "metadata": {},
   "source": [
    "# Code for registering 2d FOVs using keypoint registration\n",
    "Goal of the script:\n",
    "1) Find cells that express ChRmine ('fov')  AND that were successfully tracked across all days ('t2p')\n",
    "2) Find cells that were stimulated ('stim') AND that were successfully tracked across all days ('t2p')\n",
    "3) Export the registered 1100nm image (for downstream visualisations)\n",
    "\n",
    "Brief outline of the script:\n",
    "1) Imports all 'fov' data (usually 830nm, 920nm and 1100nm), suite2p mean fov and photostim data\n",
    "2) Motion correct raw data using Suite2p's motion correction algorithm\n",
    "3) Segment all three using cpsam TODO: (if it exists) replace this with the original segmentation (and curated segmentation) from the experimental procedure\n",
    "4) (if not existing yet) add manual keypoints to 1100nm image and the suite2p mean fov\n",
    "5) Compute affine transform that registers 1100nm ('moving') to suite2p mean fov (reference)\n",
    "6) Compute affine transform that registers stim coordinates ('moving') to suite2p mean fov (reference)\n",
    "6) Apply the appropriate transforms to keypoints, stim coordinates, 1100nm image and 1100nm segmentation, to have them all in the suite2p mean fov coordinate system\n",
    "7) Import suite2p masks for the cells that were sucessfully tracked across all days by track2p\n",
    "8) Match the stim coordinates to s2p (t2p) rois and 1100nm (fov) rois to s2p rois (using Hungarian algorithm) using euclidean distance between centroids as the metric.\n",
    "9) Threshold matches based on absolute distance (max_dist_px parameter) using euclidean distance between centroids as the metric.\n",
    "10) Visualise the overlay of all data and highlight matches\n",
    "11) Export matched indices (for stim->t2p and fov->t2p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8beec",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "Instead of recomputing the 1100nm segementation do it with the saved manual curation that was done on the first day of an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f046f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tifffile as tiff\n",
    "from skimage.transform import warp, resize\n",
    "import napari\n",
    "import yaml\n",
    "\n",
    "\n",
    "from photostim_deve.image_analysis.plot import plot_motcorr_comparison, plot_segmentation_overlay_dict, plot_image_seg_xy_stim, plot_keypoints_scatter\n",
    "from photostim_deve.image_analysis.io import get_all_fov_image, get_s2p_image, get_xy_stim, save_keypoints, load_keypoints, get_t2p_s2p_indices_session, get_s2p_rois_filt\n",
    "from photostim_deve.image_analysis.segment import segment_fov_cpsam, get_cent_from_seg\n",
    "from photostim_deve.image_analysis.register import register_keypoints_affine, match_ref_moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set params\n",
    "subject = 'jm065'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e58bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"match_stim_fov_t2p_config.yaml\", \"r\") as f:\n",
    "    cfg = yaml.safe_load(f)\n",
    "\n",
    "fov_imsize_onedim = cfg['fov_imsize_onedim']\n",
    "s2p_imsize_onedim = cfg['s2p_imsize_onedim']\n",
    "n_stim_cell = cfg['n_stim_cell']\n",
    "n_stim_ctrl = cfg['n_stim_ctrl']\n",
    "session_reg_idx = cfg['session_reg_idx']\n",
    "force_recompute = cfg['force_recompute']\n",
    "run_motcorr = cfg['run_motcorr']\n",
    "nimg_init = cfg['nimg_init']\n",
    "filt_by = cfg['filt_by']\n",
    "track2p_dirname = cfg['track2p_dirname']\n",
    "cell_prob_thr = cfg['cell_prob_thr']\n",
    "max_dist_px = cfg['max_dist_px']\n",
    "session_type = cfg['session_type']\n",
    "sat_perc = cfg['sat_perc']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db5b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "fov_imsize = (fov_imsize_onedim, fov_imsize_onedim)  # size of the FOV in pixels (assumed square)\n",
    "s2p_imsize = (s2p_imsize_onedim, s2p_imsize_onedim)  # size used for Suite2p processing (assumed square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_path = os.path.join('data_proc', 'jm', subject)\n",
    "all_session_path = sorted([os.path.join(subject_path, d) for d in os.listdir(subject_path) if os.path.isdir(os.path.join(subject_path, d)) and session_type in d])\n",
    "session_path = all_session_path[session_reg_idx]\n",
    "\n",
    "match_save_dir = os.path.join(session_path, 'match_stim_fov_t2p')\n",
    "\n",
    "keypoints_save_path = os.path.join(session_path, 'fov_reg_keypoints.csv')\n",
    "\n",
    "\n",
    "fov_s2p_px_fact = fov_imsize[0] / s2p_imsize[0] # both have the same aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7792f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fov_image = get_all_fov_image(subject_path, \n",
    "                                  session_type=session_type,\n",
    "                                  session_reg_idx = session_reg_idx, \n",
    "                                  run_motcorr=run_motcorr, \n",
    "                                  fov_imsize=fov_imsize, \n",
    "                                  nimg_init=nimg_init,\n",
    "                                  force_recompute=force_recompute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_motcorr_comparison(all_fov_image, sat_perc=sat_perc, crop=(64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a763fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fov_image_seg = segment_fov_cpsam(all_fov_image, flow_threshold=0.4, cellprob_threshold=0.0, force_recompute=force_recompute, save_path=session_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_segmentation_overlay_dict(all_fov_image_seg, sat_perc=sat_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_image = get_s2p_image(session_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3978ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stim, y_stim = get_xy_stim(session_path, session_type=session_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba5f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_seg_xy_stim(all_fov_image['1100nm'], x_stim=x_stim, y_stim=y_stim, segmentation=all_fov_image_seg['1100nm_seg'], sat_perc=sat_perc, fov_s2p_px_fact=fov_s2p_px_fact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c923b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_image_upscaled = resize(s2p_image, fov_imsize, preserve_range=True, anti_aliasing=True).astype(s2p_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "keypoints_save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae4262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(keypoints_save_path) or force_recompute:\n",
    "\n",
    "    viewer = napari.Viewer()\n",
    "\n",
    "    viewer.add_image(s2p_image_upscaled, name='s2p_mean_image', colormap='green', contrast_limits=(np.percentile(s2p_image_upscaled, 0.1), np.percentile(s2p_image_upscaled, sat_perc)))\n",
    "    viewer.add_points(name='s2p_keypoints', size=5, face_color='green')\n",
    "    viewer.add_image(all_fov_image['1100nm'], name='fov_1100nm', colormap='magenta', contrast_limits=(np.percentile(all_fov_image['1100nm'], 0.1), np.percentile(all_fov_image['1100nm'], sat_perc)))\n",
    "    viewer.add_points(name='fov_1100nm_keypoints', size=5, face_color='magenta')\n",
    "    napari.run()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acda44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(keypoints_save_path) or force_recompute:\n",
    "    save_keypoints(viewer, keypoints_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fcfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_kp_s2p, y_kp_s2p, x_kp_fov, y_kp_fov = load_keypoints(keypoints_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92debb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_kp_fov_reg, y_kp_fov_reg, transform = register_keypoints_affine(x_kp_s2p, y_kp_s2p, x_kp_fov, y_kp_fov)\n",
    "plot_keypoints_scatter(x_kp_s2p, y_kp_s2p, x_kp_fov, y_kp_fov, x_kp_fov_reg, y_kp_fov_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_stim_upscaled, y_stim_upscaled = x_stim * fov_s2p_px_fact, y_stim * fov_s2p_px_fact\n",
    "x_stim_upscaled_reg, y_stim_upscaled_reg = transform.inverse(np.stack([x_stim_upscaled, y_stim_upscaled], axis=1)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66762cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now get and transform the centroids of the 1100nm CPs\n",
    "x_fov, y_fov = get_cent_from_seg(all_fov_image_seg['1100nm_seg'])\n",
    "x_fov_reg, y_fov_reg = transform.inverse(np.stack([x_fov, y_fov], axis=1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d399d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply transform to the image\n",
    "fov_image = all_fov_image['1100nm']\n",
    "fov_image_reg = warp(fov_image, inverse_map=transform.inverse, output_shape=fov_imsize)\n",
    "\n",
    "fov_seg = all_fov_image_seg['1100nm_seg']\n",
    "fov_seg_reg = warp(fov_seg, inverse_map=transform.inverse, output_shape=fov_imsize, order=0, preserve_range=True).astype(fov_seg.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03021a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2p_image_upscaled = resize(s2p_image, fov_imsize, preserve_range=True, anti_aliasing=True).astype(s2p_image.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98a48d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2p_idxs_session = get_t2p_s2p_indices_session(subject_path, track2p_dirname=track2p_dirname, session_reg_idx=session_reg_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e141601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_s2p, x_s2p_med, y_s2p_med, idxs_filt = get_s2p_rois_filt(session_path, filt_by='t2p', t2p_idxs_session=t2p_idxs_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_s2p_med_upscaled = x_s2p_med * fov_s2p_px_fact\n",
    "y_s2p_med_upscaled = y_s2p_med * fov_s2p_px_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcd2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_ind_s2p_fov, col_ind_s2p_fov = match_ref_moving(x_s2p_med_upscaled, y_s2p_med_upscaled, x_fov_reg, y_fov_reg, max_dist_px=max_dist_px)\n",
    "row_ind_s2p_stim, col_ind_s2p_stim = match_ref_moving(x_s2p_med_upscaled, y_s2p_med_upscaled, x_stim_upscaled_reg, y_stim_upscaled_reg, max_dist_px=max_dist_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb46cc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "\n",
    "viewer.add_image(fov_image_reg, name='fov_1100nm_registered', colormap='magenta', blending='additive', contrast_limits=(np.percentile(fov_image_reg, 0.1), np.percentile(fov_image_reg, 99.9)))\n",
    "viewer.add_image(s2p_image_upscaled, name='s2p_mean_image_registered', colormap='green', blending='additive', contrast_limits=(np.percentile(s2p_image_upscaled, 0.1), np.percentile(s2p_image_upscaled, sat_perc)))\n",
    "viewer.add_image(fov_seg_reg>0, name='fov_1100nm_seg_registered', opacity=0.3, colormap='magenta')\n",
    "viewer.add_points(np.stack([x_s2p_med_upscaled, y_s2p_med_upscaled], axis=1), name='s2p_rois_medians_upscaled', size=5, face_color='green')\n",
    "viewer.add_points(np.stack([x_stim_upscaled_reg, y_stim_upscaled_reg], axis=1), name='stim_points_registered', symbol='x', size=5, face_color='cyan')\n",
    "viewer.add_points(np.stack([x_fov_reg[col_ind_s2p_fov], y_fov_reg[col_ind_s2p_fov]], axis=1), name='matched_centroids_1100nm', size=15, border_color='yellow', border_width=0.2, face_color=[0,0,0,0], opacity=0.5)\n",
    "viewer.add_points(np.stack([x_stim_upscaled_reg[col_ind_s2p_stim], y_stim_upscaled_reg[col_ind_s2p_stim]], axis=1), name='matched_stim_points', symbol='s', size=20, border_color='white', border_width=0.2, face_color=[0,0,0,0], opacity=0.5)\n",
    "napari.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate proportions\n",
    "n_stim_to_s2p = len(col_ind_s2p_stim)\n",
    "n_fov_to_s2p = len(col_ind_s2p_fov)\n",
    "n_s2p = len(x_s2p_med)\n",
    "\n",
    "prop_stim_to_s2p = n_stim_to_s2p / n_stim_cell\n",
    "prop_fov_to_s2p = n_fov_to_s2p / n_s2p\n",
    "\n",
    "print(f'Identified {n_fov_to_s2p} (/ {n_s2p}) tracked cells as expressing opsin, corresponding to: {prop_fov_to_s2p:.3f}.')\n",
    "print(f'Tracked {n_stim_to_s2p} (/ {n_stim_cell}) stimulated cells, corresponding to: {prop_stim_to_s2p:.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffdd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: export this in a format that will be easy to match with longipy\n",
    "# make a numpy array with indexes that are True for stimulated & tracked cells\n",
    "is_stim_and_t2p = row_ind_s2p_stim\n",
    "is_stim_and_t2p_idx = col_ind_s2p_stim # the index of that ROI according to the order of stimulation (from Bruker MarkPoints)\n",
    "is_fov_and_t2p = row_ind_s2p_fov\n",
    "is_fov_and_t2p_idx = col_ind_s2p_fov # the index of that ROI in the CP segmentation (for now not really needed)\n",
    "\n",
    "# Save these in the a separate folder\n",
    "if not os.path.exists(match_save_dir):\n",
    "    os.makedirs(match_save_dir)\n",
    "else:\n",
    "    print(f'Matching save directory {match_save_dir} already exists.')\n",
    "\n",
    "np.save(os.path.join(match_save_dir, 'is_stim_and_t2p.npy'), is_stim_and_t2p)\n",
    "np.save(os.path.join(match_save_dir, 'is_stim_and_t2p_idx.npy'), is_stim_and_t2p_idx)\n",
    "np.save(os.path.join(match_save_dir, 'is_fov_and_t2p.npy'), is_fov_and_t2p)\n",
    "np.save(os.path.join(match_save_dir, 'is_fov_and_t2p_idx.npy'), is_fov_and_t2p_idx)\n",
    "np.save(os.path.join(match_save_dir, 'fov_image_reg.npy'), fov_image_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fb19a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
