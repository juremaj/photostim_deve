{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "825aaf11",
   "metadata": {},
   "source": [
    "# stim_timing.ipynb (still need to reorganise substantially)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c214b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile as tf\n",
    "import os\n",
    "\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06138c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Volumes/data_jm_share/data_raw/calibration/stim_timing/'\n",
    "save_dir = 'utils/calibration_stim_timing/'\n",
    "# find and print all sessions\n",
    "sessions = [f for f in os.listdir(root)]\n",
    "sessions.sort()\n",
    "print(\"Available sessions:\")\n",
    "for s in sessions:\n",
    "    print(f\"{s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabc09f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = '2025-11-07_1isi_5ms' \n",
    "ch = 'Ch1'\n",
    "align_to = 'onset'  # 'onset' or 'peak'\n",
    "sigma = 50  # gaussian smoothing sigma in pixel time\n",
    "\n",
    "# dataset specifics (only to calculate units)\n",
    "\n",
    "stim_len = 50 if 'default' in session else session.split('_')[-1]\n",
    "stim_len = float(stim_len.replace('ms','')) if 'ms' in str(stim_len) else stim_len\n",
    "\n",
    "interstim_len = 1000 # in ms\n",
    "n_reps = 9 \n",
    "frame_period = 33.602823 # in ms \n",
    "xy_pixels = 512\n",
    "onset_threshold = 0.5 # threshold for onset detection (relative to max)\n",
    "px_time = frame_period / xy_pixels**2\n",
    "\n",
    "wind_pre_ms = 10 # in ms\n",
    "wind_post_ms = 110 # in ms\n",
    "# wind_post_ms = 52\n",
    "\n",
    "\n",
    "# now get onsets \n",
    "onsets = []\n",
    "for i in range(n_reps):\n",
    "    onset = i * (stim_len + interstim_len) + (interstim_len + stim_len)\n",
    "    # convert to px_index\n",
    "    onset = int(onset / px_time)\n",
    "    onsets.append(onset)  \n",
    "print('Calculated onsets (currently this is missaligned because of flyback time most likely):', onsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a365f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting window from frames to samples\n",
    "wind_pre = int(wind_pre_ms / px_time)\n",
    "wind_post = int(wind_post_ms / px_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5392ab4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find tseries\n",
    "session_path = os.path.join(root, session)\n",
    "tseries = [f for f in os.listdir(session_path) if f.startswith('TSeries')]\n",
    "if len(tseries) != 1:\n",
    "    raise ValueError(f\"Expected exactly one TSeries file, found {len(tseries)}: {tseries}\")\n",
    "tseries_path = os.path.join(session_path, tseries[0])\n",
    "\n",
    "# now find file with ch in name and ending in .tif\n",
    "tiff_files = [f for f in os.listdir(tseries_path) if ch in f and f.endswith('.tif')]\n",
    "if len(tiff_files) != 1:\n",
    "    raise ValueError(f\"Expected exactly one tif file with channel {ch}, found {len(tiff_files)}: {tiff_files}\")\n",
    "tiff_path = os.path.join(tseries_path, tiff_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5470b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Loading TIFF file: {tiff_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_flat = tf.imread(tiff_path).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17824aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smooth with a Gaussian filter\n",
    "tiff_smooth = gaussian_filter1d(tiff_flat, sigma=sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find peaks in the smoothed data\n",
    "if align_to == 'peak':\n",
    "    peaks, _ = find_peaks(tiff_smooth, prominence=np.max(tiff_smooth)/2, distance=512**2)  # Adjust height and distance as needed\n",
    "    \n",
    "elif align_to == 'onset':\n",
    "    #NOTE: IMPORTANT TO NOT GET CONFUSED: because of previous version of the code, here 'peaks' are actually onsets!!!\n",
    "\n",
    "    # get onsets by by binarisng based on half max of der\n",
    "    bin_tiff_smooth = tiff_smooth > (np.max(tiff_smooth) * onset_threshold)\n",
    "    derivative = np.diff(bin_tiff_smooth.astype(int), prepend=0)\n",
    "    peaks = np.where(derivative == 1)[0]\n",
    "    # filter peaks if the distance between them is less than the stim length (in px)\n",
    "    cutoff = (wind_pre + wind_post)*2 # in px\n",
    "    \n",
    "    # peaks = peaks[np.insert(np.diff(peaks) > cutoff, 0, True)]\n",
    "    # if there is a duplicate within cutoff, keep only the first one\n",
    "    filtered_peaks = []\n",
    "    previous_peak = peaks[0]\n",
    "    for peak in peaks[1:]:\n",
    "        if peak - previous_peak > cutoff:\n",
    "            filtered_peaks.append(previous_peak)\n",
    "            previous_peak = peak\n",
    "    peaks = np.array(filtered_peaks)\n",
    "    # get offsets in the same way\n",
    "    offsets = np.where(derivative == -1)[0]\n",
    "    # offsets = offsets[np.insert(np.diff(offsets) > cutoff, 0, True)]\n",
    "    filtered_offsets = []\n",
    "    last_offset = -np.inf\n",
    "    for offset in offsets:\n",
    "        if offset - last_offset > cutoff:\n",
    "            filtered_offsets.append(offset)\n",
    "            last_offset = offset\n",
    "    peaks = np.array(filtered_peaks)\n",
    "    offsets = np.array(filtered_offsets)\n",
    "    \n",
    "    print('Detected onsets at:', peaks)\n",
    "\n",
    "\n",
    "\n",
    "    # now compute all artefact durations\n",
    "    if len(offsets) != len(peaks):\n",
    "        print(f\"WARNING: Number of detected offsets ({len(offsets)}) does not match number of detected peaks ({len(peaks)}).\")\n",
    "        print('truncating to the minimum of the two.')\n",
    "        min_len = min(len(offsets), len(peaks))\n",
    "        offsets = offsets[:min_len]\n",
    "        peaks = peaks[:min_len]\n",
    "    \n",
    "    durations = offsets - peaks\n",
    "    durations_ms = durations * px_time\n",
    "\n",
    "    print('Detected artefact durations (in ms):', durations_ms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ef062",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(tiff_smooth)\n",
    "plt.scatter(np.array(peaks), np.zeros_like(np.array(peaks)), color='red', label='Stimulus Onsets')\n",
    "if align_to == 'onset':\n",
    "    plt.scatter(np.array(offsets), np.zeros_like(np.array(peaks)), color='blue', label='Calculated Onsets')\n",
    "plt.scatter(peaks, tiff_smooth[peaks], color='green', label='Empirically detected Peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a07d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now zoom in around first peak\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.plot(tiff_smooth)\n",
    "plt.scatter(np.array(onsets), np.zeros_like(np.array(onsets)), color='red', label='Stimulus Onsets')\n",
    "plt.scatter(np.array(offsets), np.zeros_like(np.array(peaks)), color='blue', label='Calculated Onsets')\n",
    "plt.scatter(peaks, tiff_smooth[peaks], color='green', label='Empirically detected Peaks')\n",
    "plt.xlim(peaks[0]-wind_pre, peaks[0]+wind_post)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0756d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_tr = np.zeros((len(peaks), wind_pre + wind_post))\n",
    "\n",
    "for i, peak in enumerate(peaks):\n",
    "    all_tr[i, :] = tiff_smooth[(peak - wind_pre):(peak + wind_post)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04fb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "label = np.arange(len(peaks)) if align_to == 'peak' else np.round(durations_ms, 1)\n",
    "plt.plot(all_tr.T, label=label)\n",
    "plt.legend(title='Duration (ms)', fontsize='small')\n",
    "plt.xlabel('Time (ms)')\n",
    "\n",
    "\n",
    "wind_npx = wind_pre + wind_post\n",
    "wind_ms = int(wind_npx * px_time)\n",
    "print(f\"Window rounded to int ms: {wind_ms} ms\")\n",
    "\n",
    "# change tics to ms with 1 decimal\n",
    "\n",
    "mean_tr = np.mean(all_tr, axis=0)\n",
    "peak_idx = np.argmax(mean_tr)\n",
    "\n",
    "# add 1 tick at peak_idx (0) and 3 peaks before and after\n",
    "tick_positions = np.linspace(mean_tr.shape[0], 0, num=7, dtype=float)\n",
    "\n",
    "tick_labels = [f\"{(pos - peak_idx) * px_time:.1f}\"\n",
    "                for pos in tick_positions]\n",
    "plt.xticks(tick_positions, tick_labels)\n",
    "\n",
    "plt.axvline(x=peak_idx, color='grey', linestyle='--', label='Peak Alignment')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('F')\n",
    "plt.title(f'Align. on peak. Session: {session}, Channel: {ch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9546e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_tr.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc14b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all trials and run power spectral density (i am looking for somethng very high freq)\n",
    "from scipy.signal import welch\n",
    "f, Pxx = welch(all_tr.flatten(), fs=1/px_time, nperseg=1024*4)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogy(f, Pxx)\n",
    "plt.xlabel('Frequency (Hz)')\n",
    "plt.ylabel('Power Spectral Density')\n",
    "plt.title('Power Spectral Density of Stimulus Artefact Signal') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee7b413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(mean_tr, color='black', label='Mean Trace')\n",
    "plt.axvline(x=peak_idx, color='grey', linestyle='--', label='Peak Alignment')\n",
    "plt.xticks(tick_positions, tick_labels)\n",
    "plt.xlabel('Time (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8395e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cbe98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
