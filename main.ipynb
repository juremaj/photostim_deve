{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23493f56",
   "metadata": {},
   "source": [
    "Helper script for looking at the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c69de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now open in napari\n",
    "import napari\n",
    "import tifffile\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5faad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data_proc'\n",
    "experimenter = 'jm'\n",
    "mouse = 'jm048'\n",
    "session = '2025-05-12_c'\n",
    "channel = 2\n",
    "plane = 0\n",
    "frame_period = 0.033602476 # exact frame period from metadata (for '30Hz' acquisition)\n",
    "fov_shape = (512, 512) # shape of the FOV in pixels\n",
    "\n",
    "# visualisation parameters\n",
    "uint12_max = 4095 * 2 # for conversion to uint8\n",
    "make_anim = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc1cdd2",
   "metadata": {},
   "source": [
    "define a loader for stimulation points (in space) and for the stimulation protocol (in time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a21f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_path = os.path.join(data_dir, experimenter, mouse, session)\n",
    "s2p_path = os.path.join(session_path, 'suite2p', f'plane{plane}')\n",
    "tiff_dir = os.path.join(s2p_path, f'reg_tif_chan{channel}')\n",
    "all_tiff_paths = [tiff_path for tiff_path in os.listdir(tiff_dir) if tiff_path.endswith('.tif')]\n",
    "all_tiff_paths.sort()\n",
    "print(s2p_path)\n",
    "print(tiff_dir)\n",
    "print(all_tiff_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5dff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary package for parsing xml\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be5289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i guess all can be loaded from the mark points? e.g. make a list of stimuli based on the parameters of the mark points file...22\n",
    "def parse_mark_points(session_path):\n",
    "    \"\"\"\n",
    "    Loads and parses the MarkPoints.xml file in the session path.\n",
    "    Returns a dictionary with the parameters of the mark points and the stimulation protocol as set in the PrairieView software.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    session_path : str\n",
    "        The path to the session directory containing the MarkPoints.xml file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mp_dict : dict\n",
    "        A dictionary with the parameters of the mark points and the stimulation protocol as set in the PrairieView software.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    mark_points_file = [f for f in os.listdir(session_path) if f.endswith('MarkPoints.xml')]\n",
    "    if len(mark_points_file) == 0:\n",
    "        raise FileNotFoundError(\"No MarkPoints.xml file found in session path\")\n",
    "    elif len(mark_points_file) > 1:\n",
    "        raise FileExistsError(\"Multiple MarkPoints.xml files found in session path\")\n",
    "    else:\n",
    "        mark_points_file = mark_points_file[0]\n",
    "    \n",
    "    print(f\"Found MarkPoints.xml file: {mark_points_file}\")\n",
    "\n",
    "    xml_data = ET.parse(os.path.join(session_path, mark_points_file))\n",
    "    root = xml_data.getroot()\n",
    "\n",
    "    mp_dict = {}\n",
    "\n",
    "    all_point_dict = []\n",
    "\n",
    "    for elem in root.iter():\n",
    "        if elem.tag != 'Point':\n",
    "            for key, value in elem.attrib.items():\n",
    "                if key not in mp_dict:\n",
    "                    mp_dict[key] = value\n",
    "                else:\n",
    "                    print(f\"Key {key} already exists in dictionary with value {mp_dict[key]}. Overwriting with value {value}.\")\n",
    "        \n",
    "        # if an element is a 'Point' treat it differently (by appending to list), since it is not unique (e. g. there can be multiple stimulation points)\n",
    "        else:\n",
    "            point_dict = {}\n",
    "            for key, value in elem.attrib.items():\n",
    "                if key not in mp_dict:\n",
    "                    point_dict[key] = value\n",
    "                else:\n",
    "                    print(f\"Key {key} already exists in dictionary with value {point_dict[key]}. Overwriting with value {value}.\")\n",
    "\n",
    "            all_point_dict.append(point_dict)\n",
    "\n",
    "\n",
    "    mp_dict['AllPoint'] = all_point_dict\n",
    "\n",
    "    return mp_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd92008",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_dict = parse_mark_points(session_path)\n",
    "for key, value in mp_dict.items():\n",
    "    print(f\"Key: {key}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a11f388",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_dict_to_stim_list(mp_dict, frame_period = 0.033602476):\n",
    "    \"\"\"\n",
    "    Convert the mark points dictionary to a list of stimulation times (in seconds), corresponding frame index and point index for each stimulation.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    mp_dict : dict\n",
    "        The mark points dictionary containing the parameters of the mark points and the stimulation protocol as set in the PrairieView software.\n",
    "    frame_period : float\n",
    "        Exact frame period from metadata used to convert from time to frame index. Default is 0.033602476 (for '30Hz' acquisition).\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    stim_times : list\n",
    "        A list of stimulation times, corresponding frame index and point index for each stimulation.\n",
    "    stim_frames : list\n",
    "        A list of frame indices for each stimulation.\n",
    "    stim_points : list\n",
    "        Index of stimulated point corresponding to each stimulation.\n",
    "\n",
    "    \"\"\"\n",
    "    initial_delay = float(mp_dict['InitialDelay'])\n",
    "    inter_point_delay = float(mp_dict['InterPointDelay'])\n",
    "    duration = float(mp_dict['Duration'])\n",
    "    repetitions = int(mp_dict['Repetitions'])\n",
    "    n_points = len(mp_dict['AllPoint'])\n",
    "\n",
    "    n_stim = n_points * repetitions\n",
    "\n",
    "    stim_times = np.zeros((n_stim))\n",
    "    stim_frames = np.zeros((n_stim))\n",
    "    stim_points = np.zeros((n_stim))\n",
    "\n",
    "    for i in range(n_stim):\n",
    "        # points go from 0 to n_points - 1 and then reset\n",
    "        stim_times[i] = (initial_delay + i * (inter_point_delay + duration)) / 1000\n",
    "        stim_frames[i] = int(stim_times[i] / frame_period)\n",
    "        stim_points[i] = i % n_points\n",
    "\n",
    "\n",
    "    return stim_times, stim_frames, stim_points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea32d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_times, stim_frames, stim_points = mp_dict_to_stim_list(mp_dict, frame_period = frame_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b57c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the protocol\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7170b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check in suite2p if it looks like it makes sense\n",
    "s2p_idx = 49 # point_idx 1: 401, 49, point_idx 2: 203, 88  \n",
    "point_idx = 1 # response to which stimulus\n",
    "f = np.load(os.path.join(s2p_path, 'F.npy'), allow_pickle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be622bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 2))\n",
    "\n",
    "for (i, frame) in enumerate(stim_frames):\n",
    "    plt.axvline(frame, color=f'C{int(stim_points[i])}', alpha=0.5)\n",
    "\n",
    "plt.plot(f[s2p_idx,:])\n",
    "plt.xlim(1600, np.max(stim_frames))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cbe6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 2))\n",
    "\n",
    "for (i, frame) in enumerate(stim_frames):\n",
    "    plt.axvline(frame, color=f'C{int(stim_points[i])}', alpha=0.5)\n",
    "\n",
    "plt.plot(f[s2p_idx,:])\n",
    "plt.xlim(1600, np.max(stim_frames))\n",
    "plt.axis('off')\n",
    "plt.xlim(2000, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "peristim_wind = [10, 30] # +- in frames\n",
    "repetitions = int(mp_dict['Repetitions'])\n",
    "\n",
    "resp_mat = np.zeros((repetitions, peristim_wind[0] + peristim_wind[1] + 1))\n",
    "\n",
    "count = 0\n",
    "for (i, point) in enumerate(stim_points):\n",
    "    frame = int(stim_frames[i])\n",
    "    if point == point_idx:\n",
    "        resp_mat[count, :] = f[s2p_idx, frame - peristim_wind[0]:frame + peristim_wind[1] + 1]\n",
    "        count += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579f6559",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(2, 2), dpi=300)\n",
    "plt.plot(resp_mat.T, color='grey', alpha=0.1)\n",
    "plt.plot(np.mean(resp_mat, axis=0), color='C0', alpha=0.5, zorder=10)\n",
    "plt.axvline(peristim_wind[0], color='k', linestyle='--')\n",
    "plt.ylabel('Fluorescence (a.u.)') \n",
    "plt.xlabel('Time (s)')\n",
    "plt.xticks([peristim_wind[0], (peristim_wind[1])/2 + peristim_wind[0], peristim_wind[1] + peristim_wind[0]], [0, 0.5, 1])     \n",
    "\n",
    "plt.figure(figsize=(2, 2), dpi=300)\n",
    "plt.imshow(resp_mat, aspect='auto', cmap='bwr', vmin=np.median(resp_mat) - 8 * np.std(resp_mat), vmax=np.median(resp_mat) + 8 * np.std(resp_mat))\n",
    "plt.axvline(peristim_wind[0], color='k', linestyle='--')\n",
    "plt.ylabel('Repetition')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.xticks([peristim_wind[0], (peristim_wind[1])/2 + peristim_wind[0], peristim_wind[1] + peristim_wind[0]], [0, 0.5, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe4db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiff = []\n",
    "for tiff_path in all_tiff_paths:\n",
    "    print(f'Loading {tiff_path}')\n",
    "    tiff = tifffile.imread(os.path.join(tiff_dir, tiff_path))\n",
    "    tiff = tiff / uint12_max * 255\n",
    "    tiff = tiff.astype(np.uint8)\n",
    "    all_tiff.append(tiff)\n",
    "    # print(f'Loaded {tiff.shape} image')\n",
    "\n",
    "all_tiff = np.concatenate(all_tiff, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8049c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute the coordinates of the stimulations\n",
    "point_coords = np.zeros((len(mp_dict['AllPoint']), 2))\n",
    "for i, point in enumerate(mp_dict['AllPoint']):\n",
    "    point_coords[i, 0] = float(point['Y']) * fov_shape[0]\n",
    "    point_coords[i, 1] = float(point['X'])  * fov_shape[1]\n",
    "\n",
    "print(point_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "ops = np.load(os.path.join(s2p_path, 'ops.npy'), allow_pickle=True).item()\n",
    "mn_image = ops['meanImg']\n",
    "\n",
    "plt.imshow(mn_image, cmap='gray', vmax=500)\n",
    "plt.scatter(point_coords[:, 1], point_coords[:, 0], c='r', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd6dda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_size = [250, 250]\n",
    "centroid = np.mean(point_coords, axis=0)\n",
    "centroid_xy_shift = [0, 0]\n",
    "\n",
    "crop_mask = np.zeros(fov_shape, dtype=bool)\n",
    "crop_mask[int(centroid[0] - box_size[0] / 2):int(centroid[0] + box_size[0] / 2), int(centroid[1] - box_size[1] / 2):int(centroid[1] + box_size[1] / 2)] = True\n",
    "crop_mn_image = mn_image[crop_mask].reshape((box_size[1], box_size[0]))\n",
    "\n",
    "crop_point_coords = point_coords - np.array([centroid[0] - box_size[0] / 2, centroid[1] - box_size[1] / 2]) + centroid_xy_shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d217cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(crop_mn_image, cmap='gray', vmax=500)\n",
    "plt.scatter(crop_point_coords[:, 1], crop_point_coords[:, 0], c='r', s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b55476b",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_tiff = all_tiff[:, crop_mask].reshape((all_tiff.shape[0], box_size[1], box_size[0]))\n",
    "# remove all_tiff from memory\n",
    "del all_tiff\n",
    "# garbage collection\n",
    "import gc\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ead4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from napari_animation import Animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d00010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now show it in gui\n",
    "labels = [1, 2, 3, 4]\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "size = 30\n",
    "properties = {'label': labels}\n",
    "\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(crop_tiff, name=f'{experimenter}_{mouse}_{session}_plane{plane}_chan{channel}', colormap='gray')\n",
    "    # add points\n",
    "    viewer.add_points(crop_point_coords, name='stimulations', size=0, properties=properties, text={'string': labels, 'color': colors, 'size': size})\n",
    "    # set frame rate to 30 fps\n",
    "\n",
    "    if make_anim:\n",
    "        anim = Animation(viewer)\n",
    "\n",
    "        for i in np.arange(4150, 4150 + 5 * 120):\n",
    "            viewer.dims.set_point(0, i)\n",
    "            anim.capture_keyframe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47ee72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if make_anim:\n",
    "    anim.animate('stim.mp4', fps=300, quality=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092997a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now make a video of the average stimulation (e.g. take the times from each stim0 and average them)\n",
    "n_frames_cycle = int(stim_frames[stim_points == 0][1] - stim_frames[stim_points == 0][0])\n",
    "\n",
    "crop_tiff_rep_avg = np.zeros((n_frames_cycle, crop_tiff.shape[1], crop_tiff.shape[2]))\n",
    "\n",
    "for i in range(int(mp_dict['Repetitions'])-2):\n",
    "    t_onset = int(stim_frames[stim_points == 0][i])\n",
    "    t_offset = int(stim_frames[stim_points == 0][i + 1])\n",
    "\n",
    "    if t_offset - t_onset != n_frames_cycle:\n",
    "        t_offset = t_onset + n_frames_cycle\n",
    "    print(i)\n",
    "    print(f'Onset: {t_onset}, Offset: {t_offset}')\n",
    "    crop_tiff_rep_avg += crop_tiff[t_onset:t_offset, :, :]\n",
    "\n",
    "    \n",
    "crop_tiff_rep_avg = crop_tiff_rep_avg / int(mp_dict['Repetitions'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b80e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_tiff_rep_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e930b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with napari.gui_qt():\n",
    "    viewer = napari.Viewer()\n",
    "    viewer.add_image(crop_tiff_rep_avg, name=f'{experimenter}_{mouse}_{session}_plane{plane}_chan{channel}', colormap='gray')\n",
    "    viewer.add_points(crop_point_coords, name='stimulations', size=0, properties=properties, text={'string': labels, 'color': colors, 'size': size})\n",
    "\n",
    "\n",
    "    if make_anim:\n",
    "        anim = Animation(viewer)\n",
    "\n",
    "        # set all frames as keyframes\n",
    "        for i in range(crop_tiff_rep_avg.shape[0]):\n",
    "            # go to frame i (dim 0 of crop_tiff_rep_avg)\n",
    "            viewer.dims.set_point(0, i)\n",
    "            anim.capture_keyframe()\n",
    "        # set the fps to 30\n",
    "\n",
    "if make_anim:\n",
    "    anim.animate('stim_avg.mp4', fps=300, quality=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01838d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average activations for each stimulus from the average\n",
    "resp_duration = 10 # in frames\n",
    "n_points = len(mp_dict['AllPoint'])\n",
    "inter_stim_interval = 30 # in frames\n",
    "# stim0_onset = 0\n",
    "# stim1_onset = 30\n",
    "# stim2_onset = 60\n",
    "# stim3_onset = 90\n",
    "\n",
    "# make the median projection be the baseline\n",
    "crop_tiff_rep_avg_median = np.median(crop_tiff_rep_avg, axis=0)\n",
    "\n",
    "all_mn_stim_resp = np.zeros((n_points, crop_tiff_rep_avg.shape[1], crop_tiff_rep_avg.shape[2]))\n",
    "\n",
    "for i in range(all_mn_stim_resp.shape[0]):\n",
    "    onset = i * inter_stim_interval\n",
    "    offset = onset + resp_duration\n",
    "    all_mn_stim_resp[i,:,:] = np.mean(crop_tiff_rep_avg[onset:offset, :, :], axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc7c5d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mn_stim_resp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5720bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_vis = 10\n",
    "\n",
    "fig, axs = plt.subplots(1, n_points, figsize=(20, 5))\n",
    "\n",
    "for i in range(all_mn_stim_resp.shape[0]):\n",
    "    diff = crop_tiff_rep_avg_median- all_mn_stim_resp[i,:,:]\n",
    "    # center on median of diff\n",
    "    diff = diff - np.median(diff)\n",
    "\n",
    "    axs[i].imshow(diff, cmap='bwr_r', vmin=np.std(diff) * -std_vis, vmax=np.std(diff) * std_vis)\n",
    "    axs[i].scatter(crop_point_coords[i, 1], crop_point_coords[i, 0], c='black', s=10)\n",
    "    # remove axis ticks and labels\n",
    "    axs[i].set_xticks([])\n",
    "    axs[i].set_yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c47a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ab4c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b713d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "napari-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
